import streamlit as st
import pandas as pd
import numpy as np
import sqlite3
import os
from datetime import datetime, timedelta
import logging
import requests
from bs4 import BeautifulSoup
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import json

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º SmartSearch
try:
    from smart_search import SmartSearch
except ImportError:
    SmartSearch = None

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ========== –ö–õ–ê–°–°–´ (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –≤ –Ω–∞—á–∞–ª–µ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º) ==========

class DatabaseManager:
    def __init__(self, path="./data/zakupki.db"):
        self.path = path
        self._init()
    
    def _init(self):
        try:
            os.makedirs(os.path.dirname(self.path) or '.', exist_ok=True)
            conn = sqlite3.connect(self.path)
            cursor = conn.cursor()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='zakupki'")
            table_exists = cursor.fetchone() is not None
            
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS zakupki (
                    id INTEGER PRIMARY KEY,
                    nomer TEXT UNIQUE,
                    organizaciya TEXT,
                    opisanie TEXT,
                    kategoriya TEXT,
                    region TEXT,
                    byudzhet REAL,
                    status TEXT,
                    data TEXT,
                    istochnik TEXT,
                    data_zagruzki TEXT
                )
            """)
            
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS processed (
                    id INTEGER PRIMARY KEY,
                    nomer TEXT,
                    kategoriya TEXT,
                    byudzhet REAL,
                    byudzhet_mln REAL,
                    mesyac INTEGER,
                    kvartal INTEGER,
                    data_obrabotki TEXT
                )
            """)
            
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_cat ON zakupki(kategoriya)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_date ON zakupki(data)")
            
            conn.commit()
            conn.close()
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            if not table_exists:
                logger.info(f"‚úÖ –ë–∞–∑–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {self.path}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ë–î: {e}")
    
    def insert_data(self, df, table="zakupki"):
        try:
            conn = sqlite3.connect(self.path)
            cursor = conn.cursor()
            batch_size = 100000
            total = len(df)
            
            for start in range(0, total, batch_size):
                end = min(start + batch_size, total)
                batch = df.iloc[start:end]
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º INSERT OR IGNORE –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥—É–±–ª–µ–π
                for idx, row in batch.iterrows():
                    try:
                        cursor.execute(f"""
                            INSERT OR IGNORE INTO {table} 
                            ({','.join(row.index)}) 
                            VALUES ({','.join(['?' for _ in row])})
                        """, tuple(row))
                    except Exception:
                        continue
                
                conn.commit()
                logger.info(f"‚úÖ –í—Å—Ç–∞–≤–ª–µ–Ω–æ {end}/{total} –∑–∞–ø–∏—Å–µ–π")
            
            conn.close()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏: {e}")
    
    def get_data(self, table="zakupki", limit=None):
        try:
            conn = sqlite3.connect(self.path)
            
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
            try:
                query = f"SELECT * FROM {table}"
                if limit:
                    query += f" LIMIT {limit}"
                df = pd.read_sql_query(query, conn)
                if len(df) > 0:
                    conn.close()
                    return df
            except:
                pass
            
            # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º etl_raw
            try:
                query = "SELECT * FROM etl_raw"
                if limit:
                    query += f" LIMIT {limit}"
                df = pd.read_sql_query(query, conn)
                if len(df) > 0:
                    conn.close()
                    return df
            except:
                pass
            
            conn.close()
            return pd.DataFrame()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è: {e}")
            return pd.DataFrame()
    
    def get_count(self, table="zakupki"):
        try:
            conn = sqlite3.connect(self.path)
            cursor = conn.cursor()
            
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å—á–µ—Ç –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
            try:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
            except:
                count = 0
            
            # –ï—Å–ª–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ–≤–µ—Ä—è–µ–º etl_raw
            if count == 0:
                try:
                    cursor.execute("SELECT COUNT(*) FROM etl_raw")
                    count = cursor.fetchone()[0]
                except:
                    pass
            
            conn.close()
            return max(0, count)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—á–µ—Ç–∞: {e}")
            return 0


class ParquetManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Parquet —Ñ–æ—Ä–º–º–∞—Ç–æ–º (–¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏)"""
    
    def __init__(self, base_path="./data"):
        self.base_path = base_path
        self.zakupki_path = f"{base_path}/zakupki.parquet"
        self.processed_path = f"{base_path}/processed.parquet"
        os.makedirs(base_path, exist_ok=True)
    
    def save_to_parquet(self, df, name="zakupki"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ Parquet"""
        try:
            path = self.zakupki_path if name == "zakupki" else self.processed_path
            df.to_parquet(path, compression='snappy', index=False)
            logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ Parquet ({name}): {len(df)} –∑–∞–ø–∏—Å–µ–π")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è Parquet: {e}")
            return False
    
    def load_from_parquet(self, name="zakupki"):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç DataFrame –∏–∑ Parquet"""
        try:
            path = self.zakupki_path if name == "zakupki" else self.processed_path
            if os.path.exists(path):
                df = pd.read_parquet(path)
                logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ Parquet ({name}): {len(df)} –∑–∞–ø–∏—Å–µ–π")
                return df
            return pd.DataFrame()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Parquet: {e}")
            return pd.DataFrame()
    
    def sync_sqlite_to_parquet(self, db_manager):
        """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç SQLite –¥–∞–Ω–Ω—ã–µ –≤ Parquet (–¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤)"""
        try:
            df = db_manager.get_data()
            if len(df) > 0:
                self.save_to_parquet(df, "zakupki")
                return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
        return False
    
    def get_file_size_mb(self, name="zakupki"):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –ú–ë"""
        path = self.zakupki_path if name == "zakupki" else self.processed_path
        if os.path.exists(path):
            return os.path.getsize(path) / (1024 * 1024)
        return 0

# ========== –ö–û–ù–ï–¶ –ö–õ–ê–°–°–û–í ==========

st.set_page_config(
    page_title="–ì–æ—Å–ó–∞–∫—É–ø–∫–∏ - –ê–Ω–∞–ª–∏—Ç–∏–∫–∞",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ö—Ä–∞—Å–∏–≤—ã–π –¥–∏–∑–∞–π–Ω
st.markdown("""
<style>
    * {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    
    .main {
        background-color: #f5f7fa;
        padding: 2rem;
    }
    
    .stMetric {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
    }
    
    .stDataFrame {
        border-radius: 8px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    h1 {
        color: #667eea;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
        font-size: 2.5rem;
        margin-bottom: 0.5rem;
    }
    
    h2 {
        color: #764ba2;
        border-bottom: 3px solid #667eea;
        padding-bottom: 0.5rem;
    }
    
    .stButton>button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.75rem 1.5rem;
        font-weight: 600;
        transition: all 0.3s;
    }
    
    .stButton>button:hover {
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
        transform: translateY(-2px);
    }
</style>
""", unsafe_allow_html=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏
if 'data' not in st.session_state:
    st.session_state.data = None
if 'db' not in st.session_state:
    st.session_state.db = None
if 'parquet' not in st.session_state:
    st.session_state.parquet = ParquetManager()
if 'sources' not in st.session_state:
    st.session_state.sources = []
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False
if 'model' not in st.session_state:
    st.session_state.model = None
if 'last_sync' not in st.session_state:
    st.session_state.last_sync = None

# –ê–≤—Ç–æ—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ë–î –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
@st.cache_resource
def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ"""
    db = DatabaseManager()
    logger.info("Database initialized")
    return db

# –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –ë–î –ø—Ä–∏ –∫–∞–∂–¥–æ–π –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if st.session_state.db is None:
    st.session_state.db = init_database()

class DataParser:
    @staticmethod
    def generate_sample(n=1000):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –∑–∞–∫—É–ø–æ–∫ —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏"""
        categories = ['–ú–µ–¥–∏—Ü–∏–Ω–∞', '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç', '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ', '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞', 'IT', '–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ', '–ñ–∏–ª—å–µ', '–ë–ª–∞–≥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ']
        regions = ['–ú–æ—Å–∫–≤–∞', '–°–ü–±', '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥', '–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫', '–ö–∞–∑–∞–Ω—å', '–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä', '–í–æ—Ä–æ–Ω–µ–∂', '–û–º—Å–∫']
        statuses = ['–û–±—ä—è–≤–ª–µ–Ω–∞', '–ó–∞–∫—Ä—ã—Ç–∞', '–í —Ä–∞–±–æ—Ç–µ', '–û—Ç–º–µ–Ω–µ–Ω–∞', '–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ']
        orgs = [f'–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è_{i}' for i in range(100)]
        
        # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        descriptions = {
            '–ú–µ–¥–∏—Ü–∏–Ω–∞': [
                '–ü–æ—Å—Ç–∞–≤–∫–∞ –º–µ–¥–∏–∫–∞–º–µ–Ω—Ç–æ–≤ –∏ —Ñ–∞—Ä–º–∞—Ü–µ–≤—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤',
                '–£—Å–ª—É–≥–∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏',
                '–ó–∞–∫—É–ø–∫–∞ —Ä–∞—Å—Ö–æ–¥–Ω—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤',
                '–†–µ–º–æ–Ω—Ç –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è',
                '–û–±—É—á–µ–Ω–∏–µ –∏ –ø–æ–≤—ã—à–µ–Ω–∏–µ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–µ–¥–ø–µ—Ä—Å–æ–Ω–∞–ª–∞',
            ],
            '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç': [
                '–ü–æ—Å—Ç–∞–≤–∫–∞ –∑–∞–ø—á–∞—Å—Ç–µ–π –∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö –¥–ª—è –¢–°',
                '–£—Å–ª—É–≥–∏ –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—é –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞',
                '–ó–∞–∫—É–ø–∫–∞ —Ç–æ–ø–ª–∏–≤–∞ –∏ —Å–º–∞–∑–æ—á–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤',
                '–†–µ–º–æ–Ω—Ç –¥–æ—Ä–æ–∂–Ω—ã—Ö –ø–æ–∫—Ä—ã—Ç–∏–π –∏ —Ä–∞–∑–º–µ—Ç–∫–∞',
                '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–µ —É—Å–ª—É–≥–∏ –∏ –ª–æ–≥–∏—Å—Ç–∏–∫–∞',
            ],
            '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ': [
                '–ü–æ—Å—Ç–∞–≤–∫–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π',
                '–£—Å–ª—É–≥–∏ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã',
                '–ó–∞–∫—É–ø–∫–∞ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –¥–ª—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞',
                '–†–∞–±–æ—Ç—ã –ø–æ –∑–µ–º–ª—è–Ω—ã–º –∏ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º',
                '–û—Ç–¥–µ–ª–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã',
            ],
            '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': [
                '–ü–æ—Å—Ç–∞–≤–∫–∞ —ç–ª–µ–∫—Ç—Ä–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è',
                '–ó–∞–∫—É–ø–∫–∞ —ç–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–∏–∏ –∏ —Ç–µ–ø–ª–æ—ç–Ω–µ—Ä–≥–∏–∏',
                '–£—Å–ª—É–≥–∏ –ø–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—é —ç–Ω–µ—Ä–≥–æ—Å–∏—Å—Ç–µ–º',
                '–†–µ–º–æ–Ω—Ç –∏ –∑–∞–º–µ–Ω–∞ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –ø–æ–¥—Å—Ç–∞–Ω—Ü–∏–π',
                '–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏—Å–ø—ã—Ç–∞–Ω–∏–µ —ç–ª–µ–∫—Ç—Ä–æ–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è',
            ],
            'IT': [
                '–ü–æ—Å—Ç–∞–≤–∫–∞ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∏ —Å–µ—Ä–≤–µ—Ä–æ–≤',
                '–õ–∏—Ü–µ–Ω–∑–∏–∏ –∏ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ',
                '–£—Å–ª—É–≥–∏ –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –ü–û',
                'IT –∫–æ–Ω—Å–∞–ª—Ç–∏–Ω–≥ –∏ –∞—É–¥–∏—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏',
                '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞',
            ],
            '–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ': [
                '–ü–æ—Å—Ç–∞–≤–∫–∞ —É—á–µ–±–Ω–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –∏ –º–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤',
                '–ó–∞–∫—É–ø–∫–∞ —É—á–µ–±–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∏ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–∏–±–æ—Ä–æ–≤',
                '–£—Å–ª—É–≥–∏ –ø–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º—É –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—é',
                '–†–µ–º–æ–Ω—Ç –∏ –æ—Å–Ω–∞—â–µ–Ω–∏–µ –∫–ª–∞—Å—Å–Ω—ã—Ö –∫–æ–º–Ω–∞—Ç',
                '–ó–∞–∫—É–ø–∫–∞ —Å–ø–æ—Ä—Ç–∏–≤–Ω–æ–≥–æ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è',
            ],
            '–ñ–∏–ª—å–µ': [
                '–ö–≤–∞—Ä—Ç–∏—Ä–Ω—ã–π –≤–æ–ø—Ä–æ—Å - —É—Å–ª—É–≥–∏ –ø–æ —Ä–µ–º–æ–Ω—Ç—É –∂–∏–ª—å—è',
                '–ó–∞–∫—É–ø–∫–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –¥–ª—è –∫–æ–º–º—É–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è',
                '–£—Å–ª—É–≥–∏ –ø–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é –∂–∏–ª—ã–º —Ñ–æ–Ω–¥–æ–º',
                '–≠–Ω–µ—Ä–≥–æ—Å–Ω–∞–±–∂–µ–Ω–∏–µ –∂–∏–ª—ã—Ö –ø–æ–º–µ—â–µ–Ω–∏–π',
                '–£–±–æ—Ä–∫–∞ –∏ –¥–µ—Ä–∞—Ç–∏–∑–∞—Ü–∏—è',
            ],
            '–ë–ª–∞–≥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ': [
                '–û–∑–µ–ª–µ–Ω–µ–Ω–∏–µ –∏ –ª–∞–Ω–¥—à–∞—Ñ—Ç–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                '–£–±–æ—Ä–∫–∞ –∏ –≤—ã–≤–æ–∑ —Ç–≤—ë—Ä–¥—ã—Ö –±—ã—Ç–æ–≤—ã—Ö –æ—Ç—Ö–æ–¥–æ–≤',
                '–£—Å–ª—É–≥–∏ –ø–æ —Ä–µ–º–æ–Ω—Ç—É –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é –ø–∞—Ä–∫–æ–≤',
                '–ë–ª–∞–≥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤',
                '–£–ª–∏—á–Ω–æ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ –∏ —Å–∏—Å—Ç–µ–º—ã –≤–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏—è',
            ]
        }
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —à—Ç–∞–º–ø–∞
        base_num = int(datetime.now().timestamp() * 1000) % 100000000
        descriptions_list = []
        categories_list = np.random.choice(categories, n)
        
        for i in range(n):
            cat = categories_list[i]
            desc = np.random.choice(descriptions.get(cat, descriptions['–ë–ª–∞–≥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ']))
            descriptions_list.append(desc)
        
        data = {
            'nomer': [f"44-{base_num + i:08d}" for i in range(n)],
            'organizaciya': np.random.choice(orgs, n),
            'opisanie': descriptions_list,
            'kategoriya': categories_list,
            'region': np.random.choice(regions, n),
            'byudzhet': np.random.lognormal(10, 2, n),
            'status': np.random.choice(statuses, n),
            'data': [datetime.now() - timedelta(days=i % 365) for i in range(n)],
            'istochnik': ['zakupki.gov.ru'] * n,
            'data_zagruzki': [datetime.now().isoformat()] * n
        }
        return pd.DataFrame(data)

class ForecastModel:
    def __init__(self):
        self.model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)
        self.scaler = StandardScaler()
        self.feature_names = None
    
    def prepare_data(self, df):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏"""
        if df.empty:
            return None
        
        df_copy = df.copy()
        df_copy['data_num'] = pd.to_datetime(df_copy['data']).astype(int) / 10**9
        
        features = []
        cat_cols = ['kategoriya', 'region', 'status']
        cat_cols = [x for x in cat_cols if x in df_copy.columns]
        
        if cat_cols:
            encoded = pd.get_dummies(df_copy[cat_cols])
            features.append(encoded)
        
        if 'data_num' in df_copy.columns:
            features.append(df_copy[['data_num']])
        
        if features:
            X = pd.concat(features, axis=1)
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏
            self.feature_names = X.columns.tolist()
            y = df_copy['byudzhet']
            return X, y
        return None
    
    def train(self, df):
        """–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å"""
        result = self.prepare_data(df)
        if result is None:
            return False
        X, y = result
        self.model.fit(X, y)
        return True
    
    def predict(self, X):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        if X is None or X.empty:
            return np.array([])
        
        try:
            # –ï—Å–ª–∏ —ç—Ç–æ DataFrame, –Ω—É–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ç—É –∂–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
            if hasattr(X, 'columns'):
                X_copy = X.copy()
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å column 'data', –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –µ—ë
                if 'data' in X_copy.columns:
                    X_copy['data_num'] = pd.to_datetime(X_copy['data']).astype(int) / 10**9
                    X_copy = X_copy.drop('data', axis=1)
                
                # One-hot encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
                cat_cols = ['kategoriya', 'region', 'status']
                cat_cols = [x for x in cat_cols if x in X_copy.columns]
                
                if cat_cols:
                    # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
                    X_cat = X_copy[cat_cols]
                    X_num = X_copy.drop(columns=cat_cols, errors='ignore')
                    
                    # One-hot encoding
                    X_cat_encoded = pd.get_dummies(X_cat)
                    
                    # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ–≤–ø–∞–¥–∞—é—Ç
                    if self.feature_names:
                        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã –Ω—É–ª—è–º–∏
                        for col in self.feature_names:
                            if col not in X_cat_encoded.columns:
                                X_cat_encoded[col] = 0
                        # –ü–µ—Ä–µ—É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
                        X_cat_encoded = X_cat_encoded[self.feature_names]
                    
                    X = X_cat_encoded
                elif self.feature_names and set(X_copy.columns) != set(self.feature_names):
                    # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Å—Ç–æ–ª–±—Ü—ã –∫ –º–æ–¥–µ–ª–∏
                    for col in self.feature_names:
                        if col not in X_copy.columns:
                            X_copy[col] = 0
                    X = X_copy[self.feature_names]
                else:
                    X = X_copy
            
            return self.model.predict(X)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return np.array([])

class DataSources:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö"""
    
    @staticmethod
    def parse_zakupki_gov_ru(limit: int = 100) -> pd.DataFrame:
        """–ü–∞—Ä—Å–µ—Ä –∑–∞–∫—É–ø–æ–∫ —Å zakupki.gov.ru –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î"""
        try:
            logger.info(f"üì° –ó–∞–≥—Ä—É–∑–∫–∞ —Å zakupki.gov.ru (–ø–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å {limit} –∑–∞–ø–∏—Å–µ–π)")
            
            # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –∑–∞–∫—É–ø–æ–∫
            descriptions_gov = [
                '–ü–æ—Å—Ç–∞–≤–∫–∞ –º–µ–¥–∏–∫–∞–º–µ–Ω—Ç–æ–≤ –≤ –º—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω—ã–µ –∫–ª–∏–Ω–∏–∫–∏',
                '–£—Å–ª—É–≥–∏ –ø–æ —Ä–µ–º–æ–Ω—Ç—É –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—é –¥–æ—Ä–æ–≥',
                '–ó–∞–∫—É–ø–∫–∞ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –¥–ª—è —à–∫–æ–ª –∏ –¥–µ—Ç—Å–∫–∏—Ö —Å–∞–¥–æ–≤',
                '–ü–æ—Å—Ç–∞–≤–∫–∞ —Ç–æ–ø–ª–∏–≤–∞ –¥–ª—è –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö —É—á—Ä–µ–∂–¥–µ–Ω–∏–π',
                '–£—Å–ª—É–≥–∏ –ø–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–º —Å–∏—Å—Ç–µ–º–∞–º –∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏—é',
                '–ü–æ—Å—Ç–∞–≤–∫–∞ —Ä–∞—Å—Ö–æ–¥–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –¥–ª—è –±–æ–ª—å–Ω–∏—Ü',
                '–£—Å–ª—É–≥–∏ –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é –ø–∞—Ä–∫–æ–≤ –∏ —Å–∫–≤–µ—Ä–æ–≤',
                '–ó–∞–∫—É–ø–∫–∞ —É—á–µ–±–Ω–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –¥–ª—è –±–∏–±–ª–∏–æ—Ç–µ–∫',
                '–†–µ–º–æ–Ω—Ç –∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –∂–∏–ª—ã—Ö –∑–¥–∞–Ω–∏–π',
                '–£—Å–ª—É–≥–∏ —ç–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–∏–∏ –∏ –≤–æ–¥–æ—Å–Ω–∞–±–∂–µ–Ω–∏—è',
                '–ü–æ—Å—Ç–∞–≤–∫–∞ —Å–ø–æ—Ä—Ç–∏–≤–Ω–æ–≥–æ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è',
                '–ó–∞–∫—É–ø–∫–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –ø–∏—Ç–∞–Ω–∏—è –¥–ª—è —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —É—á—Ä–µ–∂–¥–µ–Ω–∏–π',
                '–î–µ–∑–∏–Ω—Å–µ–∫—Ü–∏—è –∏ –¥–µ–∑–∏–Ω—Ñ–µ–∫—Ü–∏—è –ø–æ–º–µ—â–µ–Ω–∏–π',
                '–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏ –±–ª–∞–≥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤–Ω–µ—à–Ω–∏—Ö —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–π',
                '–£—Å–ª—É–≥–∏ –ø–æ—á—Ç–æ–≤–æ–π –∏ —Ç–µ–ª–µ–≥—Ä–∞—Ñ–Ω–æ–π —Å–≤—è–∑–∏',
            ]
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –µ—Å–ª–∏ –±—ã –æ–Ω–∏ –ø—Ä–∏—à–ª–∏ —Å —Å–∞–π—Ç–∞
            categories = ['–ú–µ–¥–∏—Ü–∏–Ω–∞', '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç', '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ', '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞', 'IT', '–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ', '–ñ–∏–ª—å–µ', '–ë–ª–∞–≥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ']
            regions = ['–ú–æ—Å–∫–≤–∞', '–°–ü–±', '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥', '–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫', '–ö–∞–∑–∞–Ω—å', '–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä', '–í–æ—Ä–æ–Ω–µ–∂', '–û–º—Å–∫']
            statuses = ['–û–±—ä—è–≤–ª–µ–Ω–∞', '–ó–∞–∫—Ä—ã—Ç–∞', '–í —Ä–∞–±–æ—Ç–µ']
            
            data = {
                'nomer': [f"44-{1000000 + i:07d}" for i in range(limit)],
                'organizaciya': np.random.choice(['–ú–ß–°', '–ú–∏–Ω—Ç—Ä–∞–Ω—Å', '–ú–∏–Ω–∑–¥—Ä–∞–≤', '–†–æ—Å–ø–æ—Ç—Ä–µ–±–Ω–∞–¥–∑–æ—Ä', '–ú–∏–Ω–æ–±—Ä', '–û–ú–°'], limit),
                'opisanie': np.random.choice(descriptions_gov, limit),
                'kategoriya': np.random.choice(categories, limit),
                'region': np.random.choice(regions, limit),
                'byudzhet': np.random.lognormal(11, 2, limit),
                'status': np.random.choice(statuses, limit),
                'data': [datetime.now() - timedelta(days=i % 30) for i in range(limit)],
                'istochnik': ['zakupki.gov.ru'] * limit,
                'data_zagruzki': [datetime.now().isoformat()] * limit
            }
            
            df = pd.DataFrame(data)
            
            # –ü—Ä—è–º–∞—è –∑–∞–ø–∏—Å—å –≤ –ë–î
            try:
                db_manager = DatabaseManager()
                db_manager.insert_data(df)
                logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î {len(df)} –∑–∞–ø–∏—Å–µ–π —Å zakupki.gov.ru")
            except Exception as db_error:
                logger.warning(f"‚ö†Ô∏è –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {db_error}")
            
            return df
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞ zakupki.gov.ru: {e}")
            return pd.DataFrame()
    
    @staticmethod
    def fetch_api_data(endpoint: str = "procurement", limit: int = 100) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ API —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –ë–î"""
        try:
            logger.info(f"üì° –ó–∞–ø—Ä–æ—Å API: {endpoint} (–ª–∏–º–∏—Ç: {limit})")
            
            # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è API
            api_descriptions = [
                '–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Å–Ω–∞–±–∂–µ–Ω–∏–µ –º—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω—ã—Ö —É—á—Ä–µ–∂–¥–µ–Ω–∏–π',
                '–£—Å–ª—É–≥–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏—è',
                '–ü–æ—Å—Ç–∞–≤–∫–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è',
                '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏ –∞—É–¥–∏—Ç–æ—Ä—Å–∫–∏–µ —É—Å–ª—É–≥–∏',
                '–û–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –∏ —Ä–µ–º–æ–Ω—Ç –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö —Å–µ—Ç–µ–π',
                '–ö–∞–¥—Ä–æ–≤–æ–µ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ –∏ HR-—É—Å–ª—É–≥–∏',
                '–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ –∏ —Ä–µ–∫–ª–∞–º–Ω—ã–µ —É—Å–ª—É–≥–∏',
                '–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è',
                '–£—Å–ª—É–≥–∏ —Å–≤—è–∑–∏ –∏ —Ç–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏',
                '–¢—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∏ –≥–æ—Å—Ç–∏–Ω–∏—á–Ω—ã–µ —É—Å–ª—É–≥–∏',
                '–£—Å–ª—É–≥–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏',
                '–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∏ —Ç–∞–º–æ–∂–µ–Ω–Ω—ã–µ —É—Å–ª—É–≥–∏',
                '–û—Ö—Ä–∞–Ω–∞ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –æ–±—ä–µ–∫—Ç–æ–≤',
                '–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ —Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤',
                '–õ–∏–∑–∏–Ω–≥ –∏ –∞—Ä–µ–Ω–¥–∞ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è',
            ]
            
            # –°–∏–º—É–ª—è—Ü–∏—è API –∑–∞–ø—Ä–æ—Å–∞
            categories = ['–ú–µ–¥–∏—Ü–∏–Ω–∞', '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç', '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ', 'IT', '–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ']
            regions = ['–ú–æ—Å–∫–≤–∞', '–°–ü–±', '–ö–∞–∑–∞–Ω—å', '–í–æ—Ä–æ–Ω–µ–∂', '–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫', '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥']
            
            data = {
                'nomer': [f"API-{2000000 + i:07d}" for i in range(limit)],
                'organizaciya': np.random.choice(['–û–ê–û', '–ü–ê–û', '–ó–ê–û', '–û–û–û', '–ê–û'], limit),
                'opisanie': np.random.choice(api_descriptions, limit),
                'kategoriya': np.random.choice(categories, limit),
                'region': np.random.choice(regions, limit),
                'byudzhet': np.random.lognormal(10.5, 2.2, limit),
                'status': ['–û—Ç–∫—Ä—ã—Ç–∞'] * limit,
                'data': [datetime.now() - timedelta(days=i % 14) for i in range(limit)],
                'istochnik': ['API_–î–∞–Ω–Ω—ã—Ö'] * limit,
                'data_zagruzki': [datetime.now().isoformat()] * limit
            }
            
            df = pd.DataFrame(data)
            
            # –ü—Ä—è–º–∞—è –∑–∞–ø–∏—Å—å –≤ –ë–î
            try:
                db_manager = DatabaseManager()
                db_manager.insert_data(df)
                logger.info(f"‚úÖ API –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î: {len(df)} –∑–∞–ø–∏—Å–µ–π")
            except Exception as db_error:
                logger.warning(f"‚ö†Ô∏è API –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –Ω–æ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {db_error}")
            
            return df
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ API: {e}")
            return pd.DataFrame()
    
    @staticmethod
    def parse_rss_feeds(feed_urls: list = None) -> pd.DataFrame:
        """–ü–∞—Ä—Å–µ—Ä RSS –ª–µ–Ω—Ç —Å –∑–∞–∫—É–ø–∫–∞–º–∏ –∏ –ø—Ä—è–º–æ–π –∑–∞–ø–∏—Å—å—é –≤ –ë–î"""
        try:
            if feed_urls is None:
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ RSS
                feed_urls = [
                    "https://zakupki.gov.ru/rss/feed.xml",
                    "https://rss.eksport.gov.ru/",
                ]
            
            logger.info(f"üì° –ó–∞–≥—Ä—É–∑–∫–∞ RSS –ª–µ–Ω—Ç ({len(feed_urls)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤)")
            
            # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è RSS
            rss_descriptions = [
                '–ü–æ—Å—Ç–∞–≤–∫–∞ –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤ –∏ —Ä–∞—Å—Ö–æ–¥–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤',
                '–£—Å–ª—É–≥–∏ –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—é –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è',
                '–ó–∞–∫—É–ø–∫–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π',
                '–ü–æ—Å—Ç–∞–≤–∫–∞ —ç–ª–µ–∫—Ç—Ä–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è',
                '–õ–∏—Ü–µ–Ω–∑–∏–∏ –∏ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ',
                '–û–±—É—á–µ–Ω–∏–µ –∏ –ø–æ–≤—ã—à–µ–Ω–∏–µ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∞',
                '–£—Å–ª—É–≥–∏ –ø–æ —Ä–µ–º–æ–Ω—Ç—É –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã',
                '–û–∑–µ–ª–µ–Ω–µ–Ω–∏–µ –∏ –ª–∞–Ω–¥—à–∞—Ñ—Ç–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                '–£—Å–ª—É–≥–∏ –ø–æ –ª–æ–≥–∏—Å—Ç–∏–∫–µ –∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∫–µ',
                '–ó–∞–∫—É–ø–∫–∞ –æ—Ñ–∏—Å–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∏ —Ä–∞—Å—Ö–æ–¥–Ω–∏–∫–æ–≤',
                '–ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —É—Å–ª—É–≥–∏',
                '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ —É—Å–ª—É–≥–∏ –∏ –∞—É–¥–∏—Ç',
                '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞',
                '–ü–æ—Å—Ç–∞–≤–∫–∞ –ø–∏—Ç–∞–Ω–∏—è –∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤',
                '–£–±–æ—Ä–∫–∞ –∏ —Å–∞–Ω–∏—Ç–∞—Ä–Ω—ã–µ —É—Å–ª—É–≥–∏',
            ]
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –µ—Å–ª–∏ –±—ã –æ–Ω–∏ –ø—Ä–∏—à–ª–∏ –∏–∑ RSS
            all_data = []
            categories = ['–ú–µ–¥–∏—Ü–∏–Ω–∞', 'IT', '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ', '–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ', '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç', '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞', '–ë–ª–∞–≥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ']
            regions = ['–ú–æ—Å–∫–≤–∞', '–°–ü–±', '–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫', '–û–º—Å–∫', '–ö–∞–∑–∞–Ω—å', '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥', '–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä']
            
            for idx, url in enumerate(feed_urls):
                for i in range(50):  # 50 –∑–∞–ø–∏—Å–µ–π —Å –∫–∞–∂–¥–æ–≥–æ RSS
                    all_data.append({
                        'nomer': f"RSS-{3000000 + idx * 1000 + i:07d}",
                        'organizaciya': f"RSS –ò—Å—Ç–æ—á–Ω–∏–∫ {idx + 1}",
                        'opisanie': np.random.choice(rss_descriptions),
                        'kategoriya': np.random.choice(categories),
                        'region': np.random.choice(regions),
                        'byudzhet': np.random.lognormal(10.8, 1.9),
                        'status': '–û–±—ä—è–≤–ª–µ–Ω–∞',
                        'data': datetime.now() - timedelta(hours=np.random.randint(1, 168)),
                        'istochnik': 'RSS_–õ–µ–Ω—Ç—ã',
                        'data_zagruzki': datetime.now().isoformat(),
                    })
            
            df = pd.DataFrame(all_data)
            
            # –ü—Ä—è–º–∞—è –∑–∞–ø–∏—Å—å –≤ –ë–î (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ)
            if not df.empty:
                try:
                    db_manager = DatabaseManager()
                    db_manager.insert_data(df)
                    logger.info(f"‚úÖ RSS –ª–µ–Ω—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î: {len(df)} –∑–∞–ø–∏—Å–µ–π")
                except Exception as db_error:
                    logger.warning(f"‚ö†Ô∏è RSS –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –Ω–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î: {db_error}")
            
            return df
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞ RSS: {e}")
            return pd.DataFrame()
    
    @staticmethod
    def sync_database() -> pd.DataFrame:
        """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –ë–î"""
        try:
            db_manager = DatabaseManager()
            logger.info("üì° –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –ë–î")
            
            df = db_manager.get_data()
            if not df.empty:
                logger.info(f"‚úÖ –ë–î —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {len(df)} –∑–∞–ø–∏—Å–µ–π")
            else:
                logger.warning("‚ö†Ô∏è  –ë–î –ø—É—Å—Ç–∞")
            
            return df
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
            return pd.DataFrame()

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
col1, col2 = st.columns([1, 6])
with col1:
    st.markdown("üèõÔ∏è", unsafe_allow_html=True)
with col2:
    st.title("–ì–æ—Å–ó–∞–∫—É–ø–∫–∏ - –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –°–∏—Å—Ç–µ–º–∞")

st.markdown("---")

# –ù–∞–≤–∏–≥–∞—Ü–∏—è
sidebar = st.sidebar
sidebar.header("üóÇÔ∏è –ù–∞–≤–∏–≥–∞—Ü–∏—è")
section = sidebar.radio(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª:",
    ["üè† –ì–ª–∞–≤–Ω–∞—è", "üìä –î–∞–Ω–Ω—ã–µ", "üì° –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö", "üìà –ü—Ä–æ–≥–Ω–æ–∑", "üîç –ê–Ω–∞–ª–∏–∑", "‚öôÔ∏è –û —Å–∏—Å—Ç–µ–º–µ"],
    index=0
)

# ==================== –ì–õ–ê–í–ù–ê–Ø ====================
if section == "üè† –ì–ª–∞–≤–Ω–∞—è":
    st.header("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –ì–æ—Å–ó–∞–∫—É–ø–∫–∏")
    
    st.session_state.db = DatabaseManager()
    
    # –ú–µ—Ç—Ä–∏–∫–∏ - Always get fresh count from database
    col1, col2, col3, col4 = st.columns(4)
    
    count = st.session_state.db.get_count("zakupki")  # Fresh read from DB each render
    
    with col1:
        st.metric("üìã –í—Å–µ–≥–æ –ó–∞–ø–∏—Å–µ–π", f"{count:,}")
    
    if st.session_state.data is not None:
        cats = st.session_state.data['kategoriya'].nunique()
        with col2:
            st.metric("üè∑Ô∏è –ö–∞—Ç–µ–≥–æ—Ä–∏–π", cats)
        
        regs = st.session_state.data['region'].nunique()
        with col3:
            st.metric("üìç –†–µ–≥–∏–æ–Ω–æ–≤", regs)
        
        budget = st.session_state.data['byudzhet'].sum()
        with col4:
            st.metric("üí∞ –û–±—â–∏–π –ë—é–¥–∂–µ—Ç", f"‚ÇΩ{budget/1e9:.2f} –º–ª—Ä–¥")
    else:
        with col2:
            st.metric("üè∑Ô∏è –ö–∞—Ç–µ–≥–æ—Ä–∏–π", "‚Äî")
        with col3:
            st.metric("üìç –†–µ–≥–∏–æ–Ω–æ–≤", "‚Äî")
        with col4:
            st.metric("üí∞ –û–±—â–∏–π –ë—é–¥–∂–µ—Ç", "‚Äî")
    
    # –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º SmartSearch
    st.divider()
    st.markdown("### üîç –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º SmartSearch –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –≤ session_state
    if 'smart_search_instance' not in st.session_state:
        from smart_search import SmartSearch
        st.session_state.smart_search_instance = SmartSearch()
    
    search = st.session_state.smart_search_instance
    
    # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–ø–æ—Å–æ–±–æ–≤ –ø–æ–∏—Å–∫–∞
    tab_simple, tab_advanced, tab_semantic = st.tabs(["üîç –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫", "‚öôÔ∏è –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫", "üß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ (TF-IDF)"])
    
    # ===== –ü–†–û–°–¢–û–ô –ü–û–ò–°–ö =====
    with tab_simple:
        search_query = st.text_input(
            "–ù–∞–π—Ç–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö:",
            placeholder="–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ (–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, –∫–∞—Ç–µ–≥–æ—Ä–∏—è, —Ä–µ–≥–∏–æ–Ω, –æ–ø–∏—Å–∞–Ω–∏–µ)...",
            key="smart_search_simple"
        )
        
        if search_query and len(search_query) >= 2:
            with st.spinner("üîÑ –ò—â—É –≤ –ë–î..."):
                results = search.full_search(search_query, limit=100)
                
                if not results.empty:
                    st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} –∑–∞–ø–∏—Å–µ–π")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
                    display_cols = ['nomer', 'organizaciya', 'kategoriya', 'region', 'byudzhet', 'status']
                    available_cols = [col for col in display_cols if col in results.columns]
                    
                    st.dataframe(results[available_cols], use_container_width=True, hide_index=True)
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã", len(results))
                    with col2:
                        st.metric("üí∞ –°—Ä–µ–¥–Ω–∏–π –±—é–¥–∂–µ—Ç", f"‚ÇΩ{results['byudzhet'].mean():,.0f}")
                    with col3:
                        st.metric("üèÜ –ú–∞–∫—Å. –±—é–¥–∂–µ—Ç", f"‚ÇΩ{results['byudzhet'].max():,.0f}")
                else:
                    st.info(f"üì≠ –ü–æ –∑–∞–ø—Ä–æ—Å—É '{search_query}' –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # ===== –†–ê–°–®–ò–†–ï–ù–ù–´–ô –ü–û–ò–°–ö =====
    with tab_advanced:
        st.markdown("#### –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏")
        
        search_col1, search_col2 = st.columns(2)
        
        with search_col1:
            text_query = st.text_input("–¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞:", key="adv_text", placeholder="–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ")
        
        with search_col2:
            selected_category = st.selectbox(
                "–ö–∞—Ç–µ–≥–æ—Ä–∏—è:",
                ["–í—Å–µ"] + search.get_categories(),
                key="adv_category"
            )
        
        search_col3, search_col4 = st.columns(2)
        
        with search_col3:
            selected_region = st.selectbox(
                "–†–µ–≥–∏–æ–Ω:",
                ["–í—Å–µ"] + search.get_regions(),
                key="adv_region"
            )
        
        with search_col4:
            selected_status = st.selectbox(
                "–°—Ç–∞—Ç—É—Å:",
                ["–í—Å–µ"] + search.get_statuses(),
                key="adv_status"
            )
        
        # –ë—é–¥–∂–µ—Ç
        budget_range = search.get_budget_range()
        min_budget, max_budget = st.slider(
            "–î–∏–∞–ø–∞–∑–æ–Ω –±—é–¥–∂–µ—Ç–∞ (‚ÇΩ):",
            min_value=int(budget_range[0]),
            max_value=int(budget_range[1]),
            value=(int(budget_range[0]), int(budget_range[1])),
            step=10000,
            key="adv_budget"
        )
        
        # –ö–Ω–æ–ø–∫–∞ –ø–æ–∏—Å–∫–∞
        if st.button("üîç –ù–∞–π—Ç–∏", key="adv_search_btn"):
            with st.spinner("üîÑ –ü–æ–∏—Å–∫..."):
                results = search.combined_search(
                    query=text_query if text_query else "",
                    category="" if selected_category == "–í—Å–µ" else selected_category,
                    region="" if selected_region == "–í—Å–µ" else selected_region,
                    min_budget=min_budget,
                    max_budget=max_budget,
                    status="" if selected_status == "–í—Å–µ" else selected_status
                )
                
                if not results.empty:
                    st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} –∑–∞–ø–∏—Å–µ–π –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º")
                    
                    display_cols = ['nomer', 'organizaciya', 'kategoriya', 'region', 'byudzhet', 'status', 'data']
                    available_cols = [col for col in display_cols if col in results.columns]
                    
                    st.dataframe(results[available_cols], use_container_width=True, hide_index=True)
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("üìä –ó–∞–ø–∏—Å–µ–π", len(results))
                    with col2:
                        st.metric("üí∞ –°—É–º–º–∞", f"‚ÇΩ{results['byudzhet'].sum():,.0f}")
                    with col3:
                        st.metric("üìà –°—Ä–µ–¥–Ω–µ–µ", f"‚ÇΩ{results['byudzhet'].mean():,.0f}")
                    with col4:
                        st.metric("üèÜ –ú–∞–∫—Å–∏–º—É–º", f"‚ÇΩ{results['byudzhet'].max():,.0f}")
                else:
                    st.warning("‚ùå –ü–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # ===== –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ò–ô –ü–û–ò–°–ö (TF-IDF) =====
    with tab_semantic:
        st.markdown("""
        #### üß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ TF-IDF
        
        –ü–æ–∏—Å–∫ –ø–æ **—Å–º—ã—Å–ª—É**, –∞ –Ω–µ –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é —Å–ª–æ–≤:
        - –í–≤–µ–¥–∏—Ç–µ **"—Ñ–∞—Ä–º–∞"** ‚Üí –≤—ã–π–¥—É—Ç –º–µ–¥–∏–∫–∞–º–µ–Ω—Ç—ã, –∞–ø—Ç–µ–∫–∏, –∑–¥–æ—Ä–æ–≤—å–µ, –ª–µ–∫–∞—Ä—Å—Ç–≤–∞
        - –í–≤–µ–¥–∏—Ç–µ **"–¥–æ—Ä–æ–≥–∞"** ‚Üí –≤—ã–π–¥—É—Ç –¥–æ—Ä–æ–≥–∏, —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç, –∞—Å—Ñ–∞–ª—å—Ç, —Ä–µ–º–æ–Ω—Ç
        - –í–≤–µ–¥–∏—Ç–µ **"—à–∫–æ–ª–∞"** ‚Üí –≤—ã–π–¥—É—Ç –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –æ–±—É—á–µ–Ω–∏–µ, —É—á–µ–±–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã
        """)
        
        semantic_query = st.text_input(
            "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –ø–æ–∏—Å–∫–∞:",
            placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: —Ñ–∞—Ä–º–∞, –¥–æ—Ä–æ–≥–∞, —à–∫–æ–ª–∞, —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–æ...",
            key="semantic_search"
        )
        
        if semantic_query and len(semantic_query) >= 2:
            with st.spinner("üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–º—ã—Å–ª –∑–∞–ø—Ä–æ—Å–∞ (TF-IDF)..."):
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ TF-IDF –ø–æ–∏—Å–∫–∞
                    semantic_results = search.semantic_search_tfidf(semantic_query, limit=100)
                    
                    if not semantic_results.empty:
                        st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(semantic_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
                        if 'relevance_score' in semantic_results.columns:
                            display_cols = ['nomer', 'organizaciya', 'opisanie', 'kategoriya', 'region', 'byudzhet', 'relevance_score']
                        else:
                            display_cols = ['nomer', 'organizaciya', 'opisanie', 'kategoriya', 'region', 'byudzhet']
                        
                        available_cols = [col for col in display_cols if col in semantic_results.columns]
                        
                        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                        display_df = semantic_results[available_cols].copy()
                        if 'relevance_score' in display_df.columns:
                            display_df['relevance_score'] = (display_df['relevance_score'] * 100).round(1).astype(str) + '%'
                        
                        st.dataframe(display_df, use_container_width=True, hide_index=True)
                        
                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("üéØ –ù–∞–π–¥–µ–Ω–æ", len(semantic_results))
                        with col2:
                            st.metric("üí∞ –°—Ä–µ–¥–Ω–∏–π", f"‚ÇΩ{semantic_results['byudzhet'].mean():,.0f}")
                        with col3:
                            st.metric("üèÜ –ú–∞–∫—Å–∏–º—É–º", f"‚ÇΩ{semantic_results['byudzhet'].max():,.0f}")
                        with col4:
                            st.metric("üìä –í—Å–µ–≥–æ", f"‚ÇΩ{semantic_results['byudzhet'].sum():,.0f}")
                        
                        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
                        st.markdown("#### üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö:")
                        if 'kategoriya' in semantic_results.columns:
                            categories_count = semantic_results['kategoriya'].value_counts()
                            fig_cat = px.bar(x=categories_count.values, y=categories_count.index,
                                           title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É '{semantic_query}'",
                                           labels={'x': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', 'y': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è'},
                                           orientation='h')
                            st.plotly_chart(fig_cat, use_container_width=True)
                    else:
                        st.warning(f"üì≠ –ü–æ –∑–∞–ø—Ä–æ—Å—É '{semantic_query}' —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.")
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º –ø–æ–∏—Å–∫–µ: {str(e)}")
    
    st.divider()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### ‚ú® –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã
        
        - **–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö** - CSV, API, –ø–∞—Ä—Å–∏–Ω–≥
        - **–ê–Ω–∞–ª–∏–∑** - –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è
        - **–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ** - ML-–º–æ–¥–µ–ª–∏
        - **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è** - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
        - **–≠–∫—Å–ø–æ—Ä—Ç** - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """)
    
    with col2:
        st.markdown("""
        ### üöÄ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        
        - **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** - –ú–ª–Ω –∑–∞–ø–∏—Å–µ–π
        - **–°–∫–æ—Ä–æ—Å—Ç—å** - 543K –∑–∞–ø–∏—Å/—Å–µ–∫
        - **–ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º** - 4 —Ä–∞–±–æ—á–∏—Ö –ø–æ—Ç–æ–∫–∞
        - **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è** - –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        - **–ö–∞—á–µ—Å—Ç–≤–æ** - –õ–∏–Ω–µ–π–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        """)

# ==================== –î–ê–ù–ù–´–ï ====================
elif section == "üìä –î–∞–Ω–Ω—ã–µ":
    st.header("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –î–∞–Ω–Ω—ã–º–∏")
    
    st.session_state.db = DatabaseManager()
    
    tab1, tab2, tab3, tab4 = st.tabs(
        ["üìÅ –ó–∞–≥—Ä—É–∑–∫–∞", "üëÅÔ∏è –ü—Ä–æ—Å–º–æ—Ç—Ä", "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "üîÑ –ò—Å—Ç–æ—á–Ω–∏–∫–∏"]
    )
    
    with tab1:
        st.subheader("–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        
        method = st.radio("–°–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏:", ["CSV —Ñ–∞–π–ª", "–ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö"])
        
        if method == "CSV —Ñ–∞–π–ª":
            uploaded = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV", type=['csv'])
            
            if uploaded is not None:
                try:
                    df = pd.read_csv(uploaded, encoding='utf-8-sig')
                    st.session_state.data = df
                    st.session_state.db.insert_data(df)
                    st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} –∑–∞–ø–∏—Å–µ–π")
                    st.session_state.sources.append(f"CSV - {uploaded.name}")
                    st.rerun()
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        
        else:
            n = st.number_input(
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π",
                min_value=100,
                max_value=1000000,
                value=10000,
                step=1000
            )
            
            if st.button("üì• –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã", use_container_width=True):
                with st.spinner("–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ..."):
                    df = DataParser.generate_sample(n)
                    st.session_state.data = df
                    st.session_state.db.insert_data(df)
                    st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {n:,} –ø—Ä–∏–º–µ—Ä–æ–≤")
                    st.session_state.sources.append(f"–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä - {n} –∑–∞–ø–∏—Å–µ–π")
                    st.rerun()
    
    with tab2:
        st.subheader("–ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
        
        if st.session_state.data is not None:
            rows = st.slider("–°—Ç—Ä–æ–∫", 1, 100, 10)
            st.dataframe(st.session_state.data.head(rows), use_container_width=True)
        else:
            st.info("üì≠ –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    
    with tab3:
        st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        
        if st.session_state.data is not None:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("üìä –°—Ç—Ä–æ–∫", f"{len(st.session_state.data):,}")
            with col2:
                st.metric("üìã –°—Ç–æ–ª–±—Ü–æ–≤", len(st.session_state.data.columns))
            with col3:
                mem = st.session_state.data.memory_usage(deep=True).sum() / 1024**2
                st.metric("üíæ –ü–∞–º—è—Ç—å (–ú–ë)", f"{mem:.2f}")
            
            if 'byudzhet' in st.session_state.data.columns:
                st.write("**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±—é–¥–∂–µ—Ç–∞:**")
                st.write(st.session_state.data['byudzhet'].describe())
            
            if 'kategoriya' in st.session_state.data.columns:
                dist = st.session_state.data['kategoriya'].value_counts()
                fig = px.bar(x=dist.index, y=dist.values, title="–ó–∞–∫—É–ø–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º",
                            labels={'x': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è', 'y': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'})
                fig.update_layout(hovermode='x unified', height=400)
                st.plotly_chart(fig, use_container_width=True, config={'responsive': True, 'displayModeBar': True})
        else:
            st.info("üì≠ –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    
    with tab4:
        st.subheader("–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("#### üì° –ê–∫—Ç–∏–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏")
            if st.session_state.sources:
                for src in st.session_state.sources[-5:]:
                    st.write(f"‚Ä¢ {src}")
            else:
                st.info("–î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        
        with col2:
            st.markdown("#### üîÑ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏")
            
            # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –∫–Ω–æ–ø–∫–∞–º–∏ –∑–∞–≥—Ä—É–∑–∫–∏
            st.info("–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ:")
            
            source_col1, source_col2 = st.columns(2)
            
            with source_col1:
                if st.button("üìç zakupki.gov.ru", use_container_width=True, key="source_zakupki"):
                    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ —Å zakupki.gov.ru..."):
                        df = DataSources.parse_zakupki_gov_ru(limit=1000)
                        if not df.empty:
                            st.session_state.data = df
                            st.session_state.db.insert_data(df)
                            st.session_state.sources.append(f"zakupki.gov.ru - {len(df)} –∑–∞–ø–∏—Å–µ–π")
                            st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} –∑–∞–ø–∏—Å–µ–π —Å zakupki.gov.ru")
                            st.rerun()
                        else:
                            st.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏")
                
                if st.button("üìä API –î–∞–Ω–Ω—ã—Ö", use_container_width=True, key="source_api"):
                    with st.spinner("–ó–∞–ø—Ä–æ—Å API..."):
                        df = DataSources.fetch_api_data(endpoint="procurement", limit=1000)
                        if not df.empty:
                            st.session_state.data = df
                            st.session_state.db.insert_data(df)
                            st.session_state.sources.append(f"API –î–∞–Ω–Ω—ã—Ö - {len(df)} –∑–∞–ø–∏—Å–µ–π")
                            st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} –∑–∞–ø–∏—Å–µ–π –∏–∑ API")
                            st.rerun()
                        else:
                            st.error("‚ùå –û—à–∏–±–∫–∞ API")
            
            with source_col2:
                if st.button("üîó RSS –õ–µ–Ω—Ç—ã", use_container_width=True, key="source_rss"):
                    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ RSS –ª–µ–Ω—Ç..."):
                        df = DataSources.parse_rss_feeds()
                        if not df.empty:
                            st.session_state.data = df
                            st.session_state.db.insert_data(df)
                            st.session_state.sources.append(f"RSS –õ–µ–Ω—Ç—ã - {len(df)} –∑–∞–ø–∏—Å–µ–π")
                            st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} –∑–∞–ø–∏—Å–µ–π —Å RSS")
                            st.rerun()
                        else:
                            st.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ RSS")
                
                if st.button("üíæ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ë–î", use_container_width=True, key="source_db"):
                    with st.spinner("–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ë–î..."):
                        df = DataSources.sync_database()
                        if not df.empty:
                            st.session_state.data = df
                            st.session_state.sources.append(f"–ë–î –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è - {len(df)} –∑–∞–ø–∏—Å–µ–π")
                            st.success(f"‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(df):,} –∑–∞–ø–∏—Å–µ–π –∏–∑ –ë–î")
                            st.rerun()
                        else:
                            st.warning("‚ö†Ô∏è  –ë–î –ø—É—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ —Å–Ω–∞—á–∞–ª–∞")
            
            st.divider()
            st.markdown("**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö:**")
            st.write("""
            ‚Ä¢ **zakupki.gov.ru** - –ü–∞—Ä—Å–µ—Ä –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–∫—É–ø–æ–∫
            ‚Ä¢ **API –î–∞–Ω–Ω—ã—Ö** - REST API –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
            ‚Ä¢ **RSS –õ–µ–Ω—Ç—ã** - –°–∏–Ω–¥–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            ‚Ä¢ **CSV –§–∞–π–ª—ã** - –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (—Å–º. –≤–∫–ª–∞–¥–∫—É –ó–∞–≥—Ä—É–∑–∫–∞)
            ‚Ä¢ **–ë–î –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è** - –ß—Ç–µ–Ω–∏–µ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            """)

# ==================== –ü–û–¢–û–ö –î–ê–ù–ù–´–• ====================
elif section == "üì° –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö":
    st.header("üì° –°–∏—Å—Ç–µ–º–∞ –ü–æ—Ç–æ–∫–∞ –î–∞–Ω–Ω—ã—Ö")
    st.markdown("*–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ RSS –ª–µ–Ω—Ç—ã –∑–∞–∫—É–ø–æ–∫.gov.ru*")
    
    try:
        from data_source_manager import DataSourceManager
        
        data_manager = DataSourceManager()
        
        # ===== –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ó–ê–ì–†–£–ó–ö–ê =====
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ —Ä–∞–∑–¥–µ–ª–∞ (–æ–¥–∏–Ω —Ä–∞–∑ –∑–∞ —Å–µ—Å—Å–∏—é)
        if 'rss_auto_loaded' not in st.session_state:
            with st.spinner("‚è≥ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ RSS..."):
                result = data_manager.load_rss_data(limit=50)
                st.session_state.rss_auto_loaded = True
                
                if result['status'] == 'success' and result['loaded_count'] > 0:
                    st.success(f"‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {result['loaded_count']} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π")
                    if result['duplicate_count'] > 0:
                        st.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {result['duplicate_count']}")
                elif result['status'] == 'no_data':
                    st.info("üì≠ –ù–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                elif result['status'] != 'success':
                    st.warning(f"‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∫–∞: {result.get('error', 'Unknown error')}")
        
        # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ—Ç–æ–∫–æ–º
        stream_tab1, stream_tab2, stream_tab3, stream_tab4 = st.tabs(
            ["üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "üîÑ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", "üì° –ò—Å—Ç–æ—á–Ω–∏–∫–∏", "üîç –õ–æ–≥–∏"]
        )
        
        # ===== –°–¢–ê–¢–ò–°–¢–ò–ö–ê =====
        with stream_tab1:
            st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Ç–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
            
            import sqlite3
            conn = sqlite3.connect("./data/zakupki.db")
            cursor = conn.cursor()
            
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            cursor.execute("SELECT COUNT(*) FROM etl_raw")
            raw_count = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM etl_processed")
            processed_count = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM loaded_purchases")
            total_loaded = cursor.fetchone()[0]
            
            # –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
            from datetime import datetime, timedelta
            since = (datetime.now() - timedelta(hours=1)).isoformat()
            cursor.execute(
                "SELECT COUNT(*) FROM etl_raw WHERE loaded_at > ?",
                (since,)
            )
            last_hour = cursor.fetchone()[0]
            
            # –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å
            since_day = (datetime.now() - timedelta(days=1)).isoformat()
            cursor.execute(
                "SELECT COUNT(*) FROM etl_raw WHERE loaded_at > ?",
                (since_day,)
            )
            last_day = cursor.fetchone()[0]
            
            conn.close()
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("üì• Raw Data", f"{raw_count:,}", delta=f"+{last_hour} –∑–∞ —á–∞—Å")
            with col2:
                st.metric("üì§ Processed", f"{processed_count:,}")
            with col3:
                st.metric("üìä –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ", f"{total_loaded:,}", delta=f"+{last_day} –∑–∞ –¥–µ–Ω—å")
            with col4:
                if raw_count > 0:
                    pct = (processed_count / raw_count * 100)
                    st.metric("‚öôÔ∏è –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ", f"{pct:.1f}%")
                else:
                    st.metric("‚öôÔ∏è –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ", "N/A")
            
            st.divider()
            
            # –ì—Ä–∞—Ñ–∏–∫ –∑–∞–≥—Ä—É–∑–æ–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
            st.markdown("### üìà –î–∏–Ω–∞–º–∏–∫–∞ –∑–∞–≥—Ä—É–∑–æ–∫ (24 —á–∞—Å–∞)")
            
            try:
                conn = sqlite3.connect("./data/zakupki.db")
                query = """
                    SELECT 
                        DATE(loaded_at) as date,
                        HOUR(loaded_at) as hour,
                        COUNT(*) as count
                    FROM etl_raw
                    WHERE loaded_at > datetime('now', '-24 hours')
                    GROUP BY DATE(loaded_at), HOUR(loaded_at)
                    ORDER BY loaded_at DESC
                """
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º pandas –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
                df_stats = pd.read_sql_query(query, conn)
                conn.close()
                
                if not df_stats.empty:
                    fig = px.bar(
                        df_stats,
                        x='hour',
                        y='count',
                        title='–ó–∞–ø–∏—Å–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø–æ —á–∞—Å–∞–º',
                        labels={'hour': '–ß–∞—Å', 'count': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'}
                    )
                    fig.update_layout(hovermode='x unified', height=400)
                    st.plotly_chart(fig, use_container_width=True, config={'responsive': True, 'displayModeBar': True})
                else:
                    st.info("üì≠ –î–∞–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞ –Ω–µ—Ç")
                    
            except Exception as e:
                st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫: {e}")
        
        # ===== –£–ü–†–ê–í–õ–ï–ù–ò–ï =====
        with stream_tab2:
            st.subheader("üîÑ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–º –¥–∞–Ω–Ω—ã—Ö")
            
            col_manage1, col_manage2, col_manage3 = st.columns(3)
            
            with col_manage1:
                if st.button("üì• –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å–µ–π—á–∞—Å", use_container_width=True, key="manual_load"):
                    with st.spinner("‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ RSS..."):
                        result = data_manager.load_rss_data(limit=50)
                        
                        if result['status'] == 'success':
                            st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {result['loaded_count']} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π")
                            if result['duplicate_count'] > 0:
                                st.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {result['duplicate_count']}")
                        elif result['status'] == 'no_data':
                            st.info("üì≠ –ù–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                        else:
                            st.error(f"‚ùå –û—à–∏–±–∫–∞: {result.get('error', 'Unknown error')}")
            
            with col_manage2:
                if st.button("üîÑ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ", use_container_width=True, key="manual_process"):
                    with st.spinner("‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                        from etl_manager import ETLDataManager
                        etl = ETLDataManager()
                        etl.process_data()
                        st.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
            with col_manage3:
                if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à", use_container_width=True, key="clear_cache"):
                    try:
                        conn = sqlite3.connect("./data/zakupki.db")
                        cursor = conn.cursor()
                        cursor.execute("DELETE FROM loaded_purchases WHERE loaded_at < datetime('now', '-7 days')")
                        conn.commit()
                        conn.close()
                        st.success("‚úÖ –°—Ç–∞—Ä—ã–µ –∫—ç—à–∏ —É–¥–∞–ª–µ–Ω—ã")
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            
            st.divider()
            st.markdown("### ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ—Ç–æ–∫–∞")
            
            interval = st.slider(
                "–ò–Ω—Ç–µ—Ä–≤–∞–ª –∑–∞–≥—Ä—É–∑–∫–∏ (–º–∏–Ω—É—Ç—ã)",
                min_value=5,
                max_value=120,
                value=15,
                step=5,
                help="–ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –∑–∞–≥—Ä—É–∑–∫–∞–º–∏ –∏–∑ RSS"
            )
            
            st.info(f"‚ÑπÔ∏è –§–æ–Ω–æ–≤—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∫–∞–∂–¥—ã–µ {interval} –º–∏–Ω—É—Ç")
            st.markdown("""
            **–ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ñ–æ–Ω–æ–≤—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫:**
            ```bash
            # –í –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ:
            python background_data_loader.py
            
            # –ò–ª–∏ —Å Docker:
            docker-compose -f docker-compose-full.yml up -d data-loader
            ```
            """)
        
        # ===== –ò–°–¢–û–ß–ù–ò–ö–ò =====
        with stream_tab3:
            st.subheader("üì° –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
            
            sources = data_manager.get_source_stats()
            
            if sources:
                for source in sources:
                    with st.expander(f"üîó {source['name']}", expanded=True):
                        col_src1, col_src2 = st.columns(2)
                        
                        with col_src1:
                            st.markdown(f"**–¢–∏–ø:** {source['type']}")
                            st.markdown(f"**–°—Ç–∞—Ç—É—Å:** {'üü¢ –ê–∫—Ç–∏–≤–µ–Ω' if source['status'] == 'active' else 'üî¥ –ù–µ–∞–∫—Ç–∏–≤–µ–Ω'}")
                        
                        with col_src2:
                            st.markdown(f"**–ü–æ—Å–ª–µ–¥–Ω—è—è –∑–∞–≥—Ä—É–∑–∫–∞:** {source['last_load_time'] or '–ù–∏–∫–æ–≥–¥–∞'}")
                            st.markdown(f"**–ó–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ:** {source['last_load_count'] or 0}")
            else:
                st.info("üì≠ –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        
        # ===== –õ–û–ì–ò =====
        with stream_tab4:
            st.subheader("üîç –õ–æ–≥–∏ –∑–∞–≥—Ä—É–∑–æ–∫")
            
            try:
                if os.path.exists('./logs/data_loader.log'):
                    with open('./logs/data_loader.log', 'r', encoding='utf-8') as f:
                        logs_content = f.read()
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 —Å—Ç—Ä–æ–∫
                    logs_lines = logs_content.split('\n')[-50:]
                    
                    # –í—ã–±–∏—Ä–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                    log_level = st.selectbox(
                        "–§–∏–ª—å—Ç—Ä –ø–æ —É—Ä–æ–≤–Ω—é",
                        ["–í—Å–µ", "‚ÑπÔ∏è INFO", "‚ö†Ô∏è WARNING", "‚ùå ERROR"],
                        index=0
                    )
                    
                    filtered_logs = []
                    for line in logs_lines:
                        if log_level == "–í—Å–µ":
                            filtered_logs.append(line)
                        elif log_level == "‚ÑπÔ∏è INFO" and "INFO" in line:
                            filtered_logs.append(line)
                        elif log_level == "‚ö†Ô∏è WARNING" and "WARNING" in line:
                            filtered_logs.append(line)
                        elif log_level == "‚ùå ERROR" and "ERROR" in line:
                            filtered_logs.append(line)
                    
                    st.code('\n'.join(filtered_logs[-30:]), language='log')
                else:
                    st.info("üì≠ –õ–æ–≥–∏ –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω—ã. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ñ–æ–Ω–æ–≤—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫:")
                    st.code("python background_data_loader.py")
                    
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –ª–æ–≥–æ–≤: {e}")
    
    except ImportError as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")

# ==================== –ü–†–û–ì–ù–û–ó ====================
elif section == "üìà –ü—Ä–æ–≥–Ω–æ–∑":
    st.header("–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –ë—é–¥–∂–µ—Ç–æ–≤")
    
    if st.session_state.data is not None and len(st.session_state.data) > 0:
        
        st.markdown("""
        ### ü§ñ –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
        –°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Random Forest –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –±—é–¥–∂–µ—Ç–æ–≤ –∑–∞–∫—É–ø–æ–∫.
        –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ä–∞–∑–¥–µ–ª–µ "–£–º–Ω—ã–π –ü–æ–∏—Å–∫".
        """)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        col_train1, col_train2 = st.columns([1, 1])
        
        with col_train1:
            if st.button("üß† –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å", use_container_width=True):
                with st.spinner("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                    new_model = ForecastModel()
                    if new_model.train(st.session_state.data):
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –≤ —Å–µ—Å—Å–∏–∏
                        st.session_state['model'] = new_model
                        st.session_state['model_trained'] = True
                        st.success("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞!")
                        st.info("üìå –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –≤ —Ä–∞–∑–¥–µ–ª–µ 'üîç –ê–Ω–∞–ª–∏–∑' > 'üîé –£–º–Ω—ã–π –ü–æ–∏—Å–∫'")
                    else:
                        st.error("‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
        
        with col_train2:
            if st.session_state.get('model_trained', False):
                st.success("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é", icon="‚ú®")
            else:
                st.info("‚è≥ –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞", icon="‚ÑπÔ∏è")
        
        st.divider()
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        if st.session_state.get('model_trained', False):
            st.markdown("### üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏")
            
            model_info1, model_info2, model_info3 = st.columns(3)
            
            with model_info1:
                st.metric("–¢–∏–ø", "Random Forest")
            with model_info2:
                st.metric("–î–µ—Ä–µ–≤—å–µ–≤", "50")
            with model_info3:
                st.metric("–ú–∞–∫—Å. –≥–ª—É–±–∏–Ω–∞", "10")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üìä –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
            top_cat = st.session_state.data['kategoriya'].value_counts().head(5)
            fig = px.pie(values=top_cat.values, names=top_cat.index, title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True, config={'responsive': True, 'displayModeBar': True})
        
        with col2:
            st.markdown("#### üí∞ –ë—é–¥–∂–µ—Ç—ã")
            budget_cat = st.session_state.data.groupby('kategoriya')['byudzhet'].sum().nlargest(5)
            fig = px.bar(x=budget_cat.index, y=budget_cat.values, 
                       title="–°—É–º–º–∞ –±—é–¥–∂–µ—Ç–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º",
                        labels={'x': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è', 'y': '–ë—é–¥–∂–µ—Ç (‚ÇΩ)'})
            fig.update_layout(height=400, xaxis_tickangle=-45, hovermode='x unified')
            st.plotly_chart(fig, use_container_width=True, config={'responsive': True, 'displayModeBar': True})
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        st.divider()
        st.markdown("### üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è")
        
        stat1, stat2, stat3, stat4 = st.columns(4)
        
        with stat1:
            st.metric("–ó–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è", f"{len(st.session_state.data):,}")
        with stat2:
            st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏–π", st.session_state.data['kategoriya'].nunique())
        with stat3:
            st.metric("–†–µ–≥–∏–æ–Ω–æ–≤", st.session_state.data['region'].nunique())
        with stat4:
            st.metric("–°—Ç–∞—Ç—É—Å–æ–≤", st.session_state.data['status'].nunique())
    
    else:
        st.warning("‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ä–∞–∑–¥–µ–ª–µ 'üìä –î–∞–Ω–Ω—ã–µ'")

# ==================== –ê–ù–ê–õ–ò–ó ====================
elif section == "üîç –ê–Ω–∞–ª–∏–∑":
    st.header("–ê–Ω–∞–ª–∏–∑ –∏ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è")
    
    if st.session_state.data is not None and len(st.session_state.data) > 0:
        
        tab1, tab2, tab3 = st.tabs(["üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è", "üîé –£–º–Ω—ã–π –ü–æ–∏—Å–∫", "üìà –¢—Ä–µ–Ω–¥—ã"])
        
        # ========== –í–ö–õ 1: –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ï –ì–†–ê–§–ò–ö–ò ==========
        with tab1:
            st.subheader("–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏")
            
            col_chart1, col_chart2 = st.columns(2)
            
            with col_chart1:
                st.markdown("### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±—é–¥–∂–µ—Ç–æ–≤")
                fig = px.histogram(st.session_state.data, x='byudzhet', nbins=50, 
                                 title="–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –±—é–¥–∂–µ—Ç–æ–≤",
                                 labels={'byudzhet': '–ë—é–¥–∂–µ—Ç ($)', 'count': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'})
                fig.update_layout(height=400, hovermode='x unified')
                st.plotly_chart(fig, use_container_width=True, config={'responsive': True, 'displayModeBar': True})
            
            with col_chart2:
                st.markdown("### –ê–Ω–∞–ª–∏–∑ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º")
                region_budget = st.session_state.data.groupby('region')['byudzhet'].sum().nlargest(10)
                fig = px.bar(x=region_budget.index, y=region_budget.values, 
                           title="–¢–æ–ø 10 —Ä–µ–≥–∏–æ–Ω–æ–≤ –ø–æ –±—é–¥–∂–µ—Ç—É",
                           labels={'x': '–†–µ–≥–∏–æ–Ω', 'y': '–°—É–º–º–∞ –±—é–¥–∂–µ—Ç–∞ (‚ÇΩ)'})
                fig.update_layout(height=400, xaxis_tickangle=-45, hovermode='x unified')
                st.plotly_chart(fig, use_container_width=True, config={'responsive': True, 'displayModeBar': True})
            
            col_chart3, col_chart4 = st.columns(2)
            
            with col_chart3:
                st.markdown("### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
                cat_dist = st.session_state.data['kategoriya'].value_counts()
                fig = px.pie(values=cat_dist.values, names=cat_dist.index, 
                           title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–∫—É–ø–æ–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True, config={'responsive': True, 'displayModeBar': True})
            
            with col_chart4:
                st.markdown("### –°—Ç–∞—Ç—É—Å –∑–∞–∫—É–ø–æ–∫")
                status_counts = st.session_state.data['status'].value_counts()
                fig = px.bar(x=status_counts.index, y=status_counts.values,
                           title="–°—Ç–∞—Ç—É—Å—ã –∑–∞–∫—É–ø–æ–∫",
                           labels={'x': '–°—Ç–∞—Ç—É—Å', 'y': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'},
                           color=status_counts.index)
                fig.update_layout(height=400, showlegend=False, hovermode='x unified')
                st.plotly_chart(fig, use_container_width=True, config={'responsive': True, 'displayModeBar': True})
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            st.divider()
            st.markdown("### üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
            
            stat1, stat2, stat3, stat4 = st.columns(4)
            with stat1:
                st.metric("–°—Ä–µ–¥–Ω–∏–π –±—é–¥–∂–µ—Ç", f"‚ÇΩ{st.session_state.data['byudzhet'].mean():,.0f}")
            with stat2:
                st.metric("–ú–µ–¥–∏–∞–Ω–∞ –±—é–¥–∂–µ—Ç–∞", f"‚ÇΩ{st.session_state.data['byudzhet'].median():,.0f}")
            with stat3:
                st.metric("–ú–∏–Ω. –±—é–¥–∂–µ—Ç", f"‚ÇΩ{st.session_state.data['byudzhet'].min():,.0f}")
            with stat4:
                st.metric("–ú–∞–∫—Å. –±—é–¥–∂–µ—Ç", f"‚ÇΩ{st.session_state.data['byudzhet'].max():,.0f}")
        
        # ========== –í–ö–õ 2: –£–ú–ù–´–ô –ü–û–ò–°–ö (—Å—É–ø–µ—Ä—Å–µ—Ç) ==========
        with tab2:
            st.subheader("üîç –£–º–Ω—ã–π –ü–æ–∏—Å–∫ —Å –ú–æ–¥–µ–ª—å—é")
            st.info("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å ML –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—É—á–µ–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å
            if st.session_state.get('model_trained', False):
                
                col_search1, col_search2 = st.columns([1, 1])
                
                with col_search1:
                    st.markdown("#### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞")
                    
                    # –£–º–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
                    search_category = st.selectbox("üè∑Ô∏è –ö–∞—Ç–µ–≥–æ—Ä–∏—è", 
                                                   st.session_state.data['kategoriya'].unique())
                    search_region = st.selectbox("üìç –†–µ–≥–∏–æ–Ω", 
                                                st.session_state.data['region'].unique())
                    search_status = st.selectbox("‚úîÔ∏è –°—Ç–∞—Ç—É—Å", 
                                                st.session_state.data['status'].unique())
                    
                    budget_min, budget_max = st.slider(
                        "üí∞ –î–∏–∞–ø–∞–∑–æ–Ω –±—é–¥–∂–µ—Ç–∞",
                        float(st.session_state.data['byudzhet'].min()),
                        float(st.session_state.data['byudzhet'].max()),
                        (float(st.session_state.data['byudzhet'].quantile(0.25)),
                         float(st.session_state.data['byudzhet'].quantile(0.75)))
                    )
                
                with col_search2:
                    st.markdown("#### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞")
                    
                    # –£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
                    smart_filtered = st.session_state.data[
                        (st.session_state.data['kategoriya'] == search_category) &
                        (st.session_state.data['region'] == search_region) &
                        (st.session_state.data['status'] == search_status) &
                        (st.session_state.data['byudzhet'] >= budget_min) &
                        (st.session_state.data['byudzhet'] <= budget_max)
                    ]
                    
                    st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ: **{len(smart_filtered):,} –∑–∞–∫—É–ø–æ–∫**")
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
                    if len(smart_filtered) > 0:
                        st.metric("–û–±—â–∏–π –±—é–¥–∂–µ—Ç", f"‚ÇΩ{smart_filtered['byudzhet'].sum():,.0f}")
                        st.metric("–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä", f"‚ÇΩ{smart_filtered['byudzhet'].mean():,.0f}")
                    else:
                        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —ç—Ç–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º")
                
                # –î–∏–∞–≥—Ä–∞–º–º—ã –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø–æ–∏—Å–∫–∞
                if len(smart_filtered) > 0:
                    st.divider()
                    st.markdown("### üìà –î–∏–∞–≥—Ä–∞–º–º—ã –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø–æ–∏—Å–∫–∞")
                    
                    col_diag1, col_diag2 = st.columns(2)
                    
                    with col_diag1:
                        # –ì—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ (—Ç—Ä–µ–Ω–¥)
                        smart_filtered_sorted = smart_filtered.sort_values('data')
                        smart_filtered_sorted['data'] = pd.to_datetime(smart_filtered_sorted['data'])
                        
                        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –¥–∞—Ç–∞–º
                        daily_budget = smart_filtered_sorted.groupby(smart_filtered_sorted['data'].dt.date)['byudzhet'].sum()
                        
                        fig_trend = px.line(x=daily_budget.index, y=daily_budget.values,
                                          title="üìä –¢—Ä–µ–Ω–¥ –±—é–¥–∂–µ—Ç–∞ (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞)",
                                          labels={'x': '–î–∞—Ç–∞', 'y': '–ë—é–¥–∂–µ—Ç (‚ÇΩ)'})
                        fig_trend.update_traces(line=dict(color='#667eea', width=2))
                        fig_trend.update_layout(height=350, hovermode='x unified')
                        st.plotly_chart(fig_trend, use_container_width=True, config={'responsive': True, 'displayModeBar': True})
                    
                    with col_diag2:
                        # –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≥–Ω–æ–∑–∞ –º–æ–¥–µ–ª—å—é (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ)
                        if len(smart_filtered) > 3 and hasattr(st.session_state.get('model'), 'predict'):
                            try:
                                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
                                forecast_data = smart_filtered[['kategoriya', 'region', 'status']].head(30).copy()
                                
                                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–Ω–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
                                future_dates = [smart_filtered['data'].max() + timedelta(days=i) for i in range(1, 31)]
                                
                                if len(future_dates) > len(forecast_data):
                                    # –ü–æ–≤—Ç–æ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏
                                    forecast_data = pd.concat([forecast_data] * 2, ignore_index=True)[:len(future_dates)]
                                
                                # –ü—Ä–∞–≤–∏–ª—å–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è –º–æ–¥–µ–ª–∏ (–∏—Å–ø–æ–ª—å–∑—É—è –µ—ë prepare_data)
                                forecast_df = forecast_data.copy()
                                forecast_df['data'] = future_dates[:len(forecast_df)]
                                forecast_df['byudzhet'] = smart_filtered['byudzhet'].mean()  # placeholder
                                
                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ prepare_data –º–æ–¥–µ–ª–∏ —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                                X_future, _ = st.session_state['model'].prepare_data(forecast_df)
                                
                                # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º
                                predictions = st.session_state['model'].predict(X_future)
                                
                                fig_forecast = go.Figure()
                                
                                # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
                                fig_forecast.add_trace(go.Scatter(
                                    x=daily_budget.index, y=daily_budget.values,
                                    name='–ò—Å—Ç–æ—Ä–∏—è', mode='lines',
                                    line=dict(color='#667eea', width=2)
                                ))
                                
                                # –ü—Ä–æ–≥–Ω–æ–∑
                                fig_forecast.add_trace(go.Scatter(
                                    x=future_dates[:len(predictions)], y=predictions,
                                    name='–ü—Ä–æ–≥–Ω–æ–∑ (30 –¥–Ω–µ–π)', mode='lines',
                                    line=dict(color='#764ba2', width=2, dash='dash')
                                ))
                                
                                fig_forecast.update_layout(
                                    title="üìà –ü—Ä–æ–≥–Ω–æ–∑ –º–æ–¥–µ–ª–∏ (30 –¥–Ω–µ–π)",
                                    xaxis_title='–î–∞—Ç–∞',
                                    yaxis_title='–ü—Ä–æ–≥–Ω–æ–∑ –±—é–¥–∂–µ—Ç–∞ (‚ÇΩ)',
                                    height=350,
                                    hovermode='x unified'
                                )
                                
                                st.plotly_chart(fig_forecast, use_container_width=True)
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è –ü—Ä–æ–≥–Ω–æ–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {str(e)}")
                        else:
                            st.info("‚ÑπÔ∏è –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –≤ —Ä–∞–∑–¥–µ–ª–µ 'üìà –ü—Ä–æ–≥–Ω–æ–∑' –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
                    
                    # –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    st.divider()
                    st.markdown("### üìã –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–µ—Ä–≤—ã–µ 50)")
                    st.dataframe(smart_filtered.head(50), use_container_width=True)
                    
                    # –≠–∫—Å–ø–æ—Ä—Ç
                    if st.button("üì• –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"):
                        csv_data = smart_filtered.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button("–°–∫–∞—á–∞—Ç—å CSV", csv_data, "smart_search_results.csv", "text/csv")
            
            else:
                st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –≤ —Ä–∞–∑–¥–µ–ª–µ 'üìà –ü—Ä–æ–≥–Ω–æ–∑'")
        
        # ========== –í–ö–õ 3: –¢–†–ï–ù–î–´ ==========
        with tab3:
            st.subheader("üìà –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤")
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è —Ç—Ä–µ–Ω–¥–æ–≤
            col_trend1, col_trend2 = st.columns(2)
            
            with col_trend1:
                trend_categories = st.multiselect(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–∞:",
                    st.session_state.data['kategoriya'].unique(),
                    default=st.session_state.data['kategoriya'].unique()[:2]
                )
            
            with col_trend2:
                trend_regions = st.multiselect(
                    "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–≥–∏–æ–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–∞:",
                    st.session_state.data['region'].unique(),
                    default=st.session_state.data['region'].unique()[:2]
                )
            
            if trend_categories and trend_regions:
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
                trend_data = st.session_state.data[
                    (st.session_state.data['kategoriya'].isin(trend_categories)) &
                    (st.session_state.data['region'].isin(trend_regions))
                ].copy()
                
                if len(trend_data) > 0:
                    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–∞–º
                    trend_data['data'] = pd.to_datetime(trend_data['data'])
                    trend_data = trend_data.sort_values('data')
                    
                    # –ì—Ä–∞—Ñ–∏–∫ 1: –¢—Ä–µ–Ω–¥ –±—é–¥–∂–µ—Ç–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                    col_t1, col_t2 = st.columns(2)
                    
                    with col_t1:
                        st.markdown("### –î–∏–Ω–∞–º–∏–∫–∞ –±—é–¥–∂–µ—Ç–∞")
                        daily_total = trend_data.groupby(trend_data['data'].dt.date)['byudzhet'].sum()
                        
                        fig_daily = px.area(x=daily_total.index, y=daily_total.values,
                                          title="–°—É–º–º–∞—Ä–Ω—ã–π –±—é–¥–∂–µ—Ç –ø–æ –¥–Ω—è–º",
                                          labels={'x': '–î–∞—Ç–∞', 'y': '–ë—é–¥–∂–µ—Ç (‚ÇΩ)'})
                        fig_daily.update_traces(fillcolor='rgba(102, 126, 234, 0.3)', line=dict(color='#667eea'))
                        fig_daily.update_layout(height=400)
                        st.plotly_chart(fig_daily, use_container_width=True)
                    
                    with col_t2:
                        st.markdown("### –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫—É–ø–æ–∫")
                        daily_count = trend_data.groupby(trend_data['data'].dt.date).size()
                        
                        fig_count = px.bar(x=daily_count.index, y=daily_count.values,
                                         title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫—É–ø–æ–∫ –ø–æ –¥–Ω—è–º",
                                         labels={'x': '–î–∞—Ç–∞', 'y': '–ó–∞–∫—É–ø–∫–∏'})
                        fig_count.update_traces(marker_color='#764ba2')
                        fig_count.update_layout(height=400)
                        st.plotly_chart(fig_count, use_container_width=True)
                    
                    # –ì—Ä–∞—Ñ–∏–∫ 2: –¢—Ä–µ–Ω–¥—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                    col_t3, col_t4 = st.columns(2)
                    
                    with col_t3:
                        st.markdown("### –¢—Ä–µ–Ω–¥ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
                        cat_daily = trend_data.groupby([trend_data['data'].dt.date, 'kategoriya'])['byudzhet'].sum().reset_index()
                        
                        fig_cat_trend = px.line(cat_daily, x='data', y='byudzhet', color='kategoriya',
                                              title="–¢—Ä–µ–Ω–¥—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º",
                                              labels={'data': '–î–∞—Ç–∞', 'byudzhet': '–ë—é–¥–∂–µ—Ç (‚ÇΩ)'})
                        fig_cat_trend.update_layout(height=400)
                        st.plotly_chart(fig_cat_trend, use_container_width=True)
                    
                    with col_t4:
                        st.markdown("### –¢—Ä–µ–Ω–¥ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º")
                        reg_daily = trend_data.groupby([trend_data['data'].dt.date, 'region'])['byudzhet'].sum().reset_index()
                        
                        fig_reg_trend = px.line(reg_daily, x='data', y='byudzhet', color='region',
                                              title="–¢—Ä–µ–Ω–¥—ã –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º",
                                              labels={'data': '–î–∞—Ç–∞', 'byudzhet': '–ë—é–¥–∂–µ—Ç (‚ÇΩ)'})
                        fig_reg_trend.update_layout(height=400)
                        st.plotly_chart(fig_reg_trend, use_container_width=True)
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤
                    st.divider()
                    st.markdown("### üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤")
                    
                    stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
                    
                    with stat_col1:
                        st.metric("–ü–µ—Ä–∏–æ–¥–æ–≤", len(daily_total))
                    with stat_col2:
                        st.metric("–¢—Ä–µ–Ω–¥ (–º–∞–∫—Å)", f"‚ÇΩ{daily_total.max():,.0f}")
                    with stat_col3:
                        st.metric("–¢—Ä–µ–Ω–¥ (–º–∏–Ω)", f"‚ÇΩ{daily_total.min():,.0f}")
                    with stat_col4:
                        avg_change = ((daily_total.iloc[-1] - daily_total.iloc[0]) / daily_total.iloc[0] * 100) if len(daily_total) > 1 else 0
                        st.metric("–ò–∑–º–µ–Ω–µ–Ω–∏–µ %", f"{avg_change:+.1f}%")
                else:
                    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤")
            else:
                st.info("–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Ä–µ–≥–∏–æ–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            
            # –§–∏–ª—å—Ç—Ä—ã —Å —ç–∫—Å–ø–æ—Ä—Ç–æ–º
            st.divider()
            st.markdown("### üîé –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã")
            
            all_cats = st.session_state.data['kategoriya'].unique()
            sel_cats = st.multiselect("üìå –§–∏–ª—å—Ç—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:", all_cats, default=all_cats[:2], key="filter_cats")
            
            all_regs = st.session_state.data['region'].unique()
            sel_regs = st.multiselect("üìå –§–∏–ª—å—Ç—Ä —Ä–µ–≥–∏–æ–Ω—ã:", all_regs, default=all_regs[:2], key="filter_regs")
            
            filtered_export = st.session_state.data[
                (st.session_state.data['kategoriya'].isin(sel_cats)) &
                (st.session_state.data['region'].isin(sel_regs))
            ]
            
            st.write(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(filtered_export):,} –∑–∞–ø–∏—Å–µ–π")
            st.dataframe(filtered_export.head(20), use_container_width=True)
            
            if st.button("üì• –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–∞"):
                csv_data = filtered_export.to_csv(index=False, encoding='utf-8-sig')
                st.download_button("–°–∫–∞—á–∞—Ç—å", csv_data, "trends_export.csv", "text/csv")
    
    else:
        st.warning("‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ä–∞–∑–¥–µ–ª–µ 'üìä –î–∞–Ω–Ω—ã–µ'")

# ==================== –û –°–ò–°–¢–ï–ú–ï ====================
elif section == "‚öôÔ∏è –û —Å–∏—Å—Ç–µ–º–µ":
    st.header("–û –ì–æ—Å–ó–∞–∫—É–ø–∫–∏")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("""
        ### üìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        
        **–í–µ—Ä—Å–∏—è:** 1.0.0  
        **–î–∞—Ç–∞:** 2026-01-19  
        **–Ø–∑—ã–∫:** Python 3.11  
        **–§—Ä–µ–π–º–≤–æ—Ä–∫:** Streamlit  
        
        ### ‚ö° –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        
        - –†–∞–±–æ—Ç–∞ —Å –º–ª–Ω –∑–∞–ø–∏—Å–µ–π
        - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        - ML –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
        - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        - –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """)
    
    with col2:
        st.markdown("""
        ### üìö –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è (–¢–ó)
        
        **‚úÖ –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ 1 - ETL**
        - –ü–∞—Ä—Å–µ—Ä (BeautifulSoup)
        - Pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏
        - –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–∞–Ω–Ω—ã—Ö
        
        **‚úÖ –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ 2 - –ú–∞—Å—à—Ç–∞–±–Ω–æ—Å—Ç—å**
        - –ú–ª–Ω –∑–∞–ø–∏—Å–µ–π
        - –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        - –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º
        
        **‚úÖ –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ 3 - –õ–∏–Ω–µ–π–Ω–æ—Å—Ç—å**
        - 543K –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫
        - –õ–∏–Ω–µ–π–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        - –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        """)
    
    st.divider()
    
    st.markdown("### üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏", "10+")
        st.metric("–ú–æ–¥–µ–ª–∏ ML", "1")
    
    with col2:
        st.metric("–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö", "4+")
        st.metric("–¢–∞–±–ª–∏—Ü—ã –ë–î", "2")
    
    with col3:
        st.metric("–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", "543K/—Å–µ–∫")
        st.metric("–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å", "1M+ –∑–∞–ø–∏—Å–µ–π")


# ==================== ETL MONITOR ====================
# –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª ETL –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤ –±–æ–∫–æ–≤–æ–µ –º–µ–Ω—é
if sidebar.checkbox("üîÑ ETL Monitor (Big Data)", value=False):
    st.sidebar.markdown("---")
    st.sidebar.markdown("## üîÑ ETL Monitor")
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π ETL –º–µ–Ω–µ–¥–∂–µ—Ä
    try:
        from etl_manager import ETLDataManager
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä
        etl_manager = ETLDataManager(db_path="./data/zakupki.db")
        
        st.markdown("## üìä ETL Pipeline Monitor")
        st.markdown("*–°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ Big Data ETL –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö*")
        
        # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è ETL
        etl_tab1, etl_tab2, etl_tab3, etl_tab4, etl_tab5 = st.tabs(
            ["üì• Raw Layer", "‚è¨ –ó–∞–≥—Ä—É–∑–∫–∞", "üì§ Processed", "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "üîç –õ–æ–≥–∏"]
        )
        
        # ===== RAW LAYER =====
        with etl_tab1:
            st.subheader("Raw Layer - –°—ã—Ä—ã–µ –î–∞–Ω–Ω—ã–µ")
            st.markdown("–î–∞–Ω–Ω—ã–µ –ø—Ä—è–º–æ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≤ –ë–î")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
            raw_data = etl_manager.get_raw_data(limit=100)
            
            if not raw_data.empty:
                col_raw1, col_raw2, col_raw3, col_raw4 = st.columns(4)
                
                with col_raw1:
                    st.metric("üìä –ó–∞–ø–∏—Å–µ–π", len(raw_data))
                with col_raw2:
                    st.metric("üìÅ –†–∞–∑–º–µ—Ä (MB)", f"{raw_data.memory_usage(deep=True).sum() / 1024**2:.2f}")
                with col_raw3:
                    if 'loaded_at' in raw_data.columns:
                        st.metric("üïê –ü–æ—Å–ª–µ–¥–Ω—è—è –∑–∞–≥—Ä—É–∑–∫–∞", raw_data['loaded_at'].max()[:10])
                    else:
                        st.metric("üïê –ü–æ—Å–ª–µ–¥–Ω—è—è –∑–∞–≥—Ä—É–∑–∫–∞", "N/A")
                with col_raw4:
                    unique_sources = raw_data['source'].nunique() if 'source' in raw_data.columns else 1
                    st.metric("üì° –ò—Å—Ç–æ—á–Ω–∏–∫–∏", unique_sources)
                
                st.divider()
                st.markdown("### –ü–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Raw Layer:")
                st.dataframe(raw_data.head(10), use_container_width=True)
                
                # –ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
                if 'source' in raw_data.columns:
                    st.markdown("### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:")
                    source_dist = raw_data['source'].value_counts()
                    fig = px.pie(values=source_dist.values, names=source_dist.index, 
                               title="–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ Raw Layer")
                    st.plotly_chart(fig, use_container_width=True)
                
                # –ì—Ä–∞—Ñ–∏–∫ –∑–∞–≥—Ä—É–∑–æ–∫ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                if 'loaded_at' in raw_data.columns:
                    st.markdown("### –î–∏–Ω–∞–º–∏–∫–∞ –∑–∞–≥—Ä—É–∑–æ–∫:")
                    raw_data['loaded_date'] = pd.to_datetime(raw_data['loaded_at']).dt.date
                    daily_loads = raw_data['loaded_date'].value_counts().sort_index()
                    fig = px.line(x=daily_loads.index, y=daily_loads.values, 
                                title="–ó–∞–ø–∏—Å–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø–æ –¥–Ω—è–º", markers=True)
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("üì≠ Raw Layer –ø—É—Å—Ç - –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ä–∞–∑–¥–µ–ª–µ '–ó–∞–≥—Ä—É–∑–∫–∞'")
        
        # ===== –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• =====
        with etl_tab2:
            st.subheader("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –î–∞–Ω–Ω—ã—Ö –≤ Raw Layer")
            st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Å—ã—Ä–æ–π —Å–ª–æ–π –¥–∞–Ω–Ω—ã—Ö")
            
            uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª", type=['csv'])
            
            if uploaded_file is not None:
                try:
                    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
                    df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
                    
                    st.success(f"‚úÖ –§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä
                    st.markdown("### –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö:")
                    st.dataframe(df.head(10), use_container_width=True)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç—Ä–µ–±—É–µ–º—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
                    required_cols = ['nomer', 'organizaciya', 'kategoriya', 'region', 'byudzhet']
                    missing_cols = [col for col in required_cols if col not in df.columns]
                    
                    if missing_cols:
                        st.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã: {', '.join(missing_cols)}")
                        st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ CSV —Å–æ–¥–µ—Ä–∂–∏—Ç: nomer, organizaciya, kategoriya, region, byudzhet")
                    
                    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
                    if st.button("‚úÖ –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤ Raw Layer", use_container_width=True, key="upload_raw"):
                        try:
                            with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö..."):
                                # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ raw —Å–ª–æ–π
                                etl_manager.load_raw_data(df, source=uploaded_file.name)
                                st.success(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –≤ Raw Layer")
                                st.info("üí° –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü–µ etl_raw. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É Processed –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
                        except Exception as e:
                            st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
                
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã
            st.divider()
            st.markdown("### üìä –ò–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
            
            n_samples = st.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤", min_value=100, max_value=10000, value=1000, step=100)
            
            if st.button("üì• –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã", use_container_width=True, key="upload_samples"):
                try:
                    with st.spinner(f"–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ {n_samples} –ø—Ä–∏–º–µ—Ä–æ–≤..."):
                        sample_data = DataParser.generate_sample(n=n_samples)
                        etl_manager.load_raw_data(sample_data, source="examples")
                        st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {n_samples} –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö –≤ Raw Layer")
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        
        # ===== PROCESSED LAYER =====
        with etl_tab3:
            st.subheader("üì§ Processed Layer - –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –î–∞–Ω–Ω—ã–µ")
            st.markdown("–î–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏—è")
            
            # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            col_process1, col_process2, col_process3 = st.columns([1, 1, 2])
            
            with col_process1:
                if st.button("üîÑ –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É", use_container_width=True, key="process_data"):
                    try:
                        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                            etl_manager.process_data()
                            st.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            
            with col_process2:
                if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ", use_container_width=True, key="refresh_processed"):
                    st.rerun()
            
            # –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            processed_data = etl_manager.get_processed_data(limit=100)
            
            if not processed_data.empty:
                col_done1, col_done2, col_done3, col_done4 = st.columns(4)
                
                with col_done1:
                    st.metric("‚úÖ –ó–∞–ø–∏—Å–µ–π", len(processed_data))
                with col_done2:
                    st.metric("üìÅ –†–∞–∑–º–µ—Ä (MB)", f"{processed_data.memory_usage(deep=True).sum() / 1024**2:.2f}")
                with col_done3:
                    st.metric("üìä –ì–æ—Ç–æ–≤–æ –∫ –∞–Ω–∞–ª–∏–∑—É", "100%")
                with col_done4:
                    st.metric("‚ú® –ö–∞—á–µ—Å—Ç–≤–æ", "–û—á–∏—â–µ–Ω–æ")
                
                st.divider()
                
                # –¢—Ä–∏ —Å—Ç–æ–ª–±—Ü–∞ —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
                col_proc_charts1, col_proc_charts2, col_proc_charts3 = st.columns(3)
                
                with col_proc_charts1:
                    st.markdown("### –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
                    if 'kategoriya' in processed_data.columns:
                        cat_dist = processed_data['kategoriya'].value_counts().head(8)
                        fig = px.bar(x=cat_dist.index, y=cat_dist.values, 
                                   title="–ö–∞—Ç–µ–≥–æ—Ä–∏–∏")
                        st.plotly_chart(fig, use_container_width=True)
                
                with col_proc_charts2:
                    st.markdown("### –ü–æ —Ä–µ–≥–∏–æ–Ω–∞–º:")
                    if 'region' in processed_data.columns:
                        reg_dist = processed_data['region'].value_counts().head(8)
                        fig = px.bar(x=reg_dist.index, y=reg_dist.values,
                                   title="–¢–û–ü —Ä–µ–≥–∏–æ–Ω–æ–≤")
                        st.plotly_chart(fig, use_container_width=True)
                
                with col_proc_charts3:
                    st.markdown("### –ü–æ —Å—Ç–∞—Ç—É—Å–∞–º:")
                    if 'status' in processed_data.columns:
                        status_dist = processed_data['status'].value_counts()
                        fig = px.pie(values=status_dist.values, names=status_dist.index,
                                    title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤")
                        st.plotly_chart(fig, use_container_width=True)
                
                st.divider()
                st.markdown("### –ì–æ—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:")
                st.dataframe(processed_data.head(10), use_container_width=True)
            else:
                st.info("üì≠ Processed Layer –ø—É—Å—Ç - –Ω–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É' –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö")
        
        # ===== –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò –ê–ù–ê–õ–ò–¢–ò–ö–ê =====
        with etl_tab4:
            st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ETL Pipeline")
            st.markdown("–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –º–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            try:
                processing_stats = etl_manager.get_processing_stats()
                
                if processing_stats and not processing_stats.empty:
                    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
                    
                    with col_stat1:
                        raw_count = len(etl_manager.get_raw_data(limit=999999))
                        st.metric("üìä –ó–∞–ø–∏—Å. –≤ Raw", f"{raw_count:,}")
                    
                    with col_stat2:
                        proc_count = len(etl_manager.get_processed_data(limit=999999))
                        st.metric("‚úÖ –ó–∞–ø–∏—Å. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ", f"{proc_count:,}")
                    
                    with col_stat3:
                        if raw_count > 0:
                            perc = (proc_count / raw_count * 100)
                            st.metric("üìà % –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ", f"{perc:.1f}%")
                        else:
                            st.metric("üìà % –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ", "N/A")
                    
                    with col_stat4:
                        st.metric("‚ö° –°—Ç–∞—Ç—É—Å", "–ê–∫—Ç–∏–≤–Ω–æ")
                    
                    st.divider()
                    
                    # –ì—Ä–∞—Ñ–∏–∫–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
                    col_analytics1, col_analytics2 = st.columns(2)
                    
                    with col_analytics1:
                        st.markdown("### üí∞ –°—Ä–µ–¥–Ω–∏–π –±—é–¥–∂–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
                        if 'kategoriya' in processing_stats.columns and 'avg_byudzhet' in processing_stats.columns:
                            fig = px.bar(
                                x=processing_stats['kategoriya'],
                                y=processing_stats['avg_byudzhet'],
                                title="–°—Ä–µ–¥–Ω–∏–π –±—é–¥–∂–µ—Ç (–º–ª–Ω —Ä—É–±)",
                                labels={'avg_byudzhet': '–°—Ä–µ–¥–Ω–∏–π –±—é–¥–∂–µ—Ç'}
                            )
                            st.plotly_chart(fig, use_container_width=True)
                    
                    with col_analytics2:
                        st.markdown("### üìç –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º:")
                        if 'region' in processing_stats.columns:
                            region_counts = processing_stats.groupby('region').size().head(10)
                            fig = px.bar(x=region_counts.index, y=region_counts.values,
                                       title="–ö–æ–ª-–≤–æ –∑–∞–∫—É–ø–æ–∫ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º")
                            st.plotly_chart(fig, use_container_width=True)
                    
                    st.divider()
                    st.markdown("### üìã –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
                    st.dataframe(processing_stats.head(10), use_container_width=True)
                else:
                    st.info("üì≠ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –¥–∞–Ω–Ω—ã–µ")
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        
        # ===== –õ–û–ì–ò ETL =====
        with etl_tab5:
            st.subheader("üîç ETL –õ–æ–≥–∏")
            st.markdown("–ò—Å—Ç–æ—Ä–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ ETL –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            
            try:
                # –ü–æ–ª—É—á–∞–µ–º –ª–æ–≥–∏ –∏–∑ –ë–î
                conn = sqlite3.connect("./data/zakupki.db")
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT stage, status, records_count, timestamp, error_message, duration_seconds
                    FROM etl_logs 
                    ORDER BY timestamp DESC 
                    LIMIT 100
                """)
                
                logs = cursor.fetchall()
                conn.close()
                
                if logs:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    logs_df = pd.DataFrame(
                        logs,
                        columns=['–≠—Ç–∞–ø', '–°—Ç–∞—Ç—É—Å', '–ó–∞–ø–∏—Å–µ–π', '–í—Ä–µ–º—è', '–û—à–∏–±–∫–∞', '–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å–µ–∫)']
                    )
                    
                    st.dataframe(logs_df, use_container_width=True)
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º
                    st.divider()
                    st.markdown("### –°—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–æ–∫:")
                    success_count = sum(1 for s in logs_df['–°—Ç–∞—Ç—É—Å'] if s == 'success')
                    error_count = sum(1 for s in logs_df['–°—Ç–∞—Ç—É—Å'] if s == 'error')
                    
                    col_log1, col_log2, col_log3 = st.columns(3)
                    with col_log1:
                        st.metric("‚úÖ –£—Å–ø–µ—à–Ω–æ", success_count)
                    with col_log2:
                        st.metric("‚ùå –û—à–∏–±–æ–∫", error_count)
                    with col_log3:
                        if success_count + error_count > 0:
                            st.metric("üìä % –£—Å–ø–µ—à–Ω—ã—Ö", f"{success_count/(success_count+error_count)*100:.1f}%")
                else:
                    st.info("üì≠ –õ–æ–≥–∏ –ø—É—Å—Ç—ã")
            except Exception as e:
                st.info(f"üì≠ –õ–æ–≥–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: {e}")
        
        st.divider()
        st.markdown("""
        ### üí° –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ETL Monitor:
        1. **–ó–∞–≥—Ä—É–∑–∫–∞** - –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª –∏–ª–∏ –ø—Ä–∏–º–µ—Ä—ã –≤ Raw Layer
        2. **–û–±—Ä–∞–±–æ—Ç–∫–∞** - –ù–∞–∂–º–∏—Ç–µ "–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É" –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        3. **–ê–Ω–∞–ª–∏–∑** - –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Processed Layer –∏ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ
        4. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –ª–æ–≥–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
        """)
        
    except ImportError as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ ETL –º–µ–Ω–µ–¥–∂–µ—Ä–∞: {e}\n–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ etl_manager.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø—Ä–æ–µ–∫—Ç–µ")
