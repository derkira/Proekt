"""
–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∑–∞–∫—É–ø–æ–∫
–ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
–í—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤ –æ–±—â–∏–π ETL –ø–∞–π–ø–ª–∞–π–Ω
"""

import os
import logging
import json
from datetime import datetime
from typing import Dict, Tuple, List, Optional
from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

try:
    from pyspark.sql import SparkSession
    from pyspark.sql.functions import col, when, rand
    from pyspark.ml import Pipeline
    from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder
    from pyspark.ml.regression import LinearRegression, GBTRegressor, RandomForestRegressor
    from pyspark.ml.evaluation import RegressionEvaluator
    SPARK_AVAILABLE = True
except ImportError:
    SPARK_AVAILABLE = False

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler as SklearnScaler, LabelEncoder
from sklearn.linear_model import LinearRegression as SklearnLinearRegression
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor as SklearnRandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ProcurementDataGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–∫—É–ø–∫–∞—Ö"""
    
    @staticmethod
    def generate_data(num_records: int, random_seed: int = 42) -> pd.DataFrame:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–∫—É–ø–∫–∞—Ö"""
        np.random.seed(random_seed)
        
        logger.info(f"üîß Generating {num_records:,} procurement records")
        
        categories = [f'Category_{i}' for i in range(1, 51)]
        regions = [f'Region_{i}' for i in range(1, 31)]
        organizations = [f'Organization_{i}' for i in range(1, 201)]
        statuses = ['Open', 'Closed', 'Cancelled']
        procurement_types = ['Goods', 'Services', 'Works']
        
        data = {
            'id': range(1, num_records + 1),
            'category': np.random.choice(categories, num_records),
            'region': np.random.choice(regions, num_records),
            'organization': np.random.choice(organizations, num_records),
            'status': np.random.choice(statuses, num_records),
            'procurement_type': np.random.choice(procurement_types, num_records),
            'quantity': np.random.randint(1, 1000, num_records),
            'unit_price': np.random.lognormal(mean=8, sigma=2, size=num_records),  # Log-normal distribution
            'supplier_rating': np.random.uniform(0, 5, num_records),
            'contract_duration_days': np.random.randint(1, 365, num_records),
            'competitive_level': np.random.randint(1, 5, num_records),  # 1 = no competition, 4 = high competition
            'advance_payment_pct': np.random.uniform(0, 50, num_records),
        }
        
        df = pd.DataFrame(data)
        
        # Target variable: total_cost
        df['total_cost'] = (
            df['quantity'] * df['unit_price'] *
            (1 + np.random.normal(0, 0.1, num_records)) *  # Random variation
            (0.5 + 0.5 * df['competitive_level'] / 4)  # Higher competition = more cost
        )
        
        logger.info(f"‚úì Generated {len(df):,} records")
        logger.info(f"  Cost range: {df['total_cost'].min():,.0f} - {df['total_cost'].max():,.0f}")
        
        return df


class ProcurementMLModel:
    """ML –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∑–∞–∫—É–ø–æ–∫"""
    
    def __init__(self, model_type: str = 'gradient_boosting'):
        self.model_type = model_type
        self.model = None
        self.scaler = SklearnScaler()
        self.label_encoders = {}
        self.feature_columns = None
        self.categorical_columns = ['category', 'region', 'organization', 'status', 'procurement_type']
        self.numerical_columns = ['quantity', 'unit_price', 'supplier_rating', 'contract_duration_days',
                                 'competitive_level', 'advance_payment_pct']
        self.metrics = {}
    
    def prepare_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        logger.info("üîÑ Preparing data for training")
        
        df_copy = df.copy()
        
        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        for col in self.categorical_columns:
            if col not in self.label_encoders:
                self.label_encoders[col] = LabelEncoder()
                df_copy[col] = self.label_encoders[col].fit_transform(df_copy[col])
            else:
                df_copy[col] = self.label_encoders[col].transform(df_copy[col])
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X = df_copy[self.categorical_columns + self.numerical_columns].copy()
        X = self.scaler.fit_transform(X)
        
        # Target
        y = df_copy['total_cost'].values
        
        self.feature_columns = self.categorical_columns + self.numerical_columns
        
        logger.info(f"‚úì Data prepared: {X.shape}")
        return X, y
    
    def train(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        logger.info(f"üéì Training {self.model_type} model")
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
        if self.model_type == 'linear':
            self.model = SklearnLinearRegression()
        elif self.model_type == 'gradient_boosting':
            self.model = GradientBoostingRegressor(
                n_estimators=100, learning_rate=0.1, max_depth=5,
                random_state=42, verbose=0
            )
        elif self.model_type == 'random_forest':
            self.model = SklearnRandomForestRegressor(
                n_estimators=50, max_depth=10, random_state=42,
                n_jobs=-1
            )
        else:
            raise ValueError(f"Unknown model type: {self.model_type}")
        
        # –û–±—É—á–µ–Ω–∏–µ
        self.model.fit(X_train, y_train)
        
        # –û—Ü–µ–Ω–∫–∞
        y_train_pred = self.model.predict(X_train)
        y_test_pred = self.model.predict(X_test)
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        train_mse = mean_squared_error(y_train, y_train_pred)
        test_mse = mean_squared_error(y_test, y_test_pred)
        train_r2 = r2_score(y_train, y_train_pred)
        test_r2 = r2_score(y_test, y_test_pred)
        train_mae = mean_absolute_error(y_train, y_train_pred)
        test_mae = mean_absolute_error(y_test, y_test_pred)
        
        self.metrics = {
            'train_mse': train_mse,
            'test_mse': test_mse,
            'train_rmse': np.sqrt(train_mse),
            'test_rmse': np.sqrt(test_mse),
            'train_r2': train_r2,
            'test_r2': test_r2,
            'train_mae': train_mae,
            'test_mae': test_mae,
            'train_size': len(X_train),
            'test_size': len(X_test)
        }
        
        logger.info(f"‚úì Model trained")
        logger.info(f"  Train RMSE: {self.metrics['train_rmse']:,.0f}")
        logger.info(f"  Test RMSE: {self.metrics['test_rmse']:,.0f}")
        logger.info(f"  Train R¬≤: {self.metrics['train_r2']:.4f}")
        logger.info(f"  Test R¬≤: {self.metrics['test_r2']:.4f}")
        
        return self.metrics
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        if self.model is None:
            raise ValueError("Model not trained yet")
        return self.model.predict(X)
    
    def save(self, path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        Path(path).parent.mkdir(parents=True, exist_ok=True)
        joblib.dump({
            'model': self.model,
            'scaler': self.scaler,
            'label_encoders': self.label_encoders,
            'feature_columns': self.feature_columns,
            'metrics': self.metrics
        }, path)
        logger.info(f"‚úì Model saved: {path}")
    
    def load(self, path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        data = joblib.load(path)
        self.model = data['model']
        self.scaler = data['scaler']
        self.label_encoders = data['label_encoders']
        self.feature_columns = data['feature_columns']
        self.metrics = data['metrics']
        logger.info(f"‚úì Model loaded: {path}")


class DataVolumeImpactAnalyzer:
    """–ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏"""
    
    def __init__(self):
        self.results = []
    
    def analyze(self, data_sizes: List[int], model_type: str = 'gradient_boosting') -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –æ–±—ä–µ–º–∞ –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å"""
        logger.info("\n" + "="*60)
        logger.info(f"üìä Analyzing impact of data volume on model accuracy")
        logger.info(f"   Model type: {model_type}")
        logger.info("="*60)
        
        generator = ProcurementDataGenerator()
        
        for size in data_sizes:
            logger.info(f"\nüî¨ Testing with {size:,} records")
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            df = generator.generate_data(size)
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model = ProcurementMLModel(model_type=model_type)
            X, y = model.prepare_data(df)
            metrics = model.train(X, y)
            
            result = {
                'data_size': size,
                'model_type': model_type,
                **metrics
            }
            self.results.append(result)
        
        return {'results': self.results}
    
    def visualize_impact(self, output_dir: str = './data/ml_analysis'):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–ª–∏—è–Ω–∏—è –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö"""
        if not self.results:
            logger.warning("No results to visualize")
            return
        
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        df_results = pd.DataFrame(self.results)
        
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        fig.suptitle('Impact of Data Volume on Model Accuracy', fontsize=16, fontweight='bold')
        
        # 1. Test RMSE vs Data Size
        ax1 = axes[0, 0]
        ax1.plot(df_results['data_size'] / 1_000_000, df_results['test_rmse'],
                marker='o', linewidth=2, markersize=8)
        ax1.set_xlabel('Data Size (Millions of Records)')
        ax1.set_ylabel('Test RMSE')
        ax1.set_title('Prediction Error vs Data Size')
        ax1.grid(True, alpha=0.3)
        
        # 2. R¬≤ Score vs Data Size
        ax2 = axes[0, 1]
        ax2.plot(df_results['data_size'] / 1_000_000, df_results['test_r2'],
                marker='s', linewidth=2, markersize=8, color='green')
        ax2.set_xlabel('Data Size (Millions of Records)')
        ax2.set_ylabel('R¬≤ Score')
        ax2.set_title('Model Accuracy vs Data Size')
        ax2.set_ylim([0, 1])
        ax2.grid(True, alpha=0.3)
        
        # 3. Train vs Test R¬≤
        ax3 = axes[1, 0]
        x_pos = np.arange(len(df_results))
        ax3.bar(x_pos - 0.2, df_results['train_r2'], 0.4, label='Train R¬≤')
        ax3.bar(x_pos + 0.2, df_results['test_r2'], 0.4, label='Test R¬≤')
        ax3.set_xlabel('Data Size')
        ax3.set_ylabel('R¬≤ Score')
        ax3.set_title('Overfitting Analysis')
        ax3.set_xticks(x_pos)
        ax3.set_xticklabels([f"{s/1e6:.1f}M" for s in df_results['data_size']])
        ax3.legend()
        ax3.grid(True, alpha=0.3, axis='y')
        
        # 4. MAE vs Data Size
        ax4 = axes[1, 1]
        ax4.plot(df_results['data_size'] / 1_000_000, df_results['test_mae'],
                marker='^', linewidth=2, markersize=8, color='red')
        ax4.set_xlabel('Data Size (Millions of Records)')
        ax4.set_ylabel('Mean Absolute Error')
        ax4.set_title('Mean Prediction Error vs Data Size')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        output_path = os.path.join(output_dir, 'data_volume_impact.png')
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        logger.info(f"‚úì Visualization saved: {output_path}")
        plt.close()
    
    def save_results(self, output_dir: str = './data/ml_analysis'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # JSON
        json_path = os.path.join(output_dir, 'ml_analysis_results.json')
        with open(json_path, 'w') as f:
            json.dump(self.results, f, indent=2)
        logger.info(f"‚úì Results saved: {json_path}")
        
        # CSV
        csv_path = os.path.join(output_dir, 'ml_analysis_results.csv')
        pd.DataFrame(self.results).to_csv(csv_path, index=False)
        logger.info(f"‚úì CSV saved: {csv_path}")


class IntegratedMLPipeline:
    """–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω ML —Å ETL"""
    
    def __init__(self):
        self.data_generator = ProcurementDataGenerator()
        self.models = {}
        self.impact_analyzer = DataVolumeImpactAnalyzer()
    
    def run_full_analysis(self, output_dir: str = './data/ml_analysis'):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        logger.info("\n" + "="*60)
        logger.info("üöÄ Starting Integrated ML Pipeline")
        logger.info("="*60)
        
        # –†–∞–∑–º–µ—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        data_sizes = [100_000, 500_000, 1_000_000]
        
        # –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –æ–±—ä–µ–º–∞
        self.impact_analyzer.analyze(data_sizes, model_type='gradient_boosting')
        self.impact_analyzer.visualize_impact(output_dir)
        self.impact_analyzer.save_results(output_dir)
        
        logger.info("\n" + "="*60)
        logger.info("‚úì ML Pipeline completed")
        logger.info("="*60)
    
    def train_and_deploy_model(self, data_size: int = 1_000_000):
        """–û–±—É—á–µ–Ω–∏–µ –∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        logger.info("\n" + "="*60)
        logger.info("üéì Training Production Model")
        logger.info("="*60)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        df = self.data_generator.generate_data(data_size)
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        model_types = ['linear', 'gradient_boosting', 'random_forest']
        
        for model_type in model_types:
            logger.info(f"\nüîß Training {model_type} model")
            
            model = ProcurementMLModel(model_type=model_type)
            X, y = model.prepare_data(df)
            metrics = model.train(X, y)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model_path = f'./models/procurement_model_{model_type}.pkl'
            model.save(model_path)
            
            self.models[model_type] = model


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("\n" + "#"*60)
    logger.info("# PROCUREMENT ML MODEL TRAINING")
    logger.info("#"*60)
    
    try:
        # –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
        pipeline = IntegratedMLPipeline()
        
        # –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö
        pipeline.run_full_analysis()
        
        # –û–±—É—á–µ–Ω–∏–µ production –º–æ–¥–µ–ª–∏
        pipeline.train_and_deploy_model(data_size=1_000_000)
        
        logger.info("\n" + "#"*60)
        logger.info("‚úì ML TRAINING COMPLETED")
        logger.info("#"*60)
        
    except Exception as e:
        logger.error(f"‚úó Error: {e}", exc_info=True)


if __name__ == "__main__":
    main()
